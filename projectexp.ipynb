{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9bb3ed884a5f43d984a258683971da65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48fe27ce952c42b1ac617d80da266503",
              "IPY_MODEL_23d6d75233fe4bfab73d16bff1ce795d",
              "IPY_MODEL_7dc94aa4ca474504ab0628936eed00d0"
            ],
            "layout": "IPY_MODEL_efa1e6ce1deb4731b7b9703a302674ff"
          }
        },
        "48fe27ce952c42b1ac617d80da266503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ee269ddaa64c0d9aa053ea99b346b1",
            "placeholder": "​",
            "style": "IPY_MODEL_7be3013d451d4cb2bd0abf12b6be09f3",
            "value": "Map: 100%"
          }
        },
        "23d6d75233fe4bfab73d16bff1ce795d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b38184c138d437f8ebaed9c89a01a23",
            "max": 2490,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2ea7a12df8c48c393c75df476667b14",
            "value": 2490
          }
        },
        "7dc94aa4ca474504ab0628936eed00d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db217e246144b6fbf508d2b443c7033",
            "placeholder": "​",
            "style": "IPY_MODEL_2c5e152195fa4a109de0c57abbfa7bd6",
            "value": " 2490/2490 [00:00&lt;00:00, 12328.94 examples/s]"
          }
        },
        "efa1e6ce1deb4731b7b9703a302674ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ee269ddaa64c0d9aa053ea99b346b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be3013d451d4cb2bd0abf12b6be09f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b38184c138d437f8ebaed9c89a01a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ea7a12df8c48c393c75df476667b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1db217e246144b6fbf508d2b443c7033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c5e152195fa4a109de0c57abbfa7bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51a2dab6689f400cbd0ffa21ee78c063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_904d74328fa94dd9a5f059e9accc8450",
              "IPY_MODEL_59eca621f49045798db2f6bbe19ce043",
              "IPY_MODEL_b2e4d06d86124b9ba9af305ea96c7a7a"
            ],
            "layout": "IPY_MODEL_de648ee9e05f479db05067b33c73505e"
          }
        },
        "904d74328fa94dd9a5f059e9accc8450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84880dc055864f4d89790ee7e6467a67",
            "placeholder": "​",
            "style": "IPY_MODEL_e51bbf4d3b674ddc9debff70fe356fae",
            "value": "Map: 100%"
          }
        },
        "59eca621f49045798db2f6bbe19ce043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1cb93d4766429aa84856adf589eb49",
            "max": 277,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_213199e89f444a4295987fe361cc2d0d",
            "value": 277
          }
        },
        "b2e4d06d86124b9ba9af305ea96c7a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93fb5dff1854083802524b93b84d92f",
            "placeholder": "​",
            "style": "IPY_MODEL_7b1af174db224dbfba9beca1086834cf",
            "value": " 277/277 [00:00&lt;00:00, 7712.98 examples/s]"
          }
        },
        "de648ee9e05f479db05067b33c73505e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84880dc055864f4d89790ee7e6467a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51bbf4d3b674ddc9debff70fe356fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee1cb93d4766429aa84856adf589eb49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213199e89f444a4295987fe361cc2d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c93fb5dff1854083802524b93b84d92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b1af174db224dbfba9beca1086834cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f9b02967c794e9b828e618cbd07a639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3a6accb53b84bc68c692614885ba9d2",
              "IPY_MODEL_3c6448f1a24f4bf38d84d457333f83e4",
              "IPY_MODEL_6fde40d02c0646b0b860d62b194adc3f"
            ],
            "layout": "IPY_MODEL_19ac0c8627b44e3a8022662902b648fe"
          }
        },
        "c3a6accb53b84bc68c692614885ba9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e0d19ca7c141da9f53d220dd35188e",
            "placeholder": "​",
            "style": "IPY_MODEL_708a9200a23a446ea24854794ba33e38",
            "value": "Map: 100%"
          }
        },
        "3c6448f1a24f4bf38d84d457333f83e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d643035408743158291d03fd570823e",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbff790471cc4fd1a2b22301e51a904a",
            "value": 3000
          }
        },
        "6fde40d02c0646b0b860d62b194adc3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fd1fa69cbc34c4a92c64622e560e54b",
            "placeholder": "​",
            "style": "IPY_MODEL_9be506953834483aa31dccf4e9f8de3e",
            "value": " 3000/3000 [00:00&lt;00:00, 17260.40 examples/s]"
          }
        },
        "19ac0c8627b44e3a8022662902b648fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e0d19ca7c141da9f53d220dd35188e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "708a9200a23a446ea24854794ba33e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d643035408743158291d03fd570823e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbff790471cc4fd1a2b22301e51a904a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fd1fa69cbc34c4a92c64622e560e54b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9be506953834483aa31dccf4e9f8de3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"HF_INPUTE_YOUR_API\"\n"
      ],
      "metadata": {
        "id": "0o-UqWhdC9Yo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeYjlQjrazhH",
        "outputId": "8dc54a82-08f2-4229-f8b3-d5ef65ff436a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 14 18:14:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   44C    P0             57W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HLjFfmxMPDzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Shenxuanyi-cmu/FederatedLLM\n",
        "%cd FederatedLLM\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAIFmQ-Ca9ss",
        "outputId": "df68e8cb-1d6e-4869-a690-06b30463e254"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FederatedLLM'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 40 (delta 4), reused 39 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (40/40), 40.80 MiB | 19.39 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "/content/FederatedLLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '/bitsandbytes/d' requirements.txt\n",
        "!sed -i '/jllllll\\/bitsandbytes-wheels/d' requirements.txt"
      ],
      "metadata": {
        "id": "4SESvpOZbPwi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt --upgrade --quiet\n",
        "\n",
        "!pip install -U \"transformers>=4.46.0\" \"accelerate>=1.0.0\" \"peft>=0.13.0\" --quiet\n",
        "\n",
        "!pip install -U \"bitsandbytes>=0.45.0\" --quiet\n",
        "\n",
        "!python -m bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soMOZEDZbQvS",
        "outputId": "69d3ab95-c6c7-4ace-e77c-6720c908aacb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.2/510.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.5/508.5 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.0.6, 3.5.0, 3.7.0, 3.17.0, 4.0.0, 4.0.1, 4.0.2, 4.0.3, 4.0.4, 4.0.5, 4.0.7, 4.0.8, 4.0.9, 4.1.2, 4.1.6, 4.2.6, 4.2.7, 4.3.13, 4.3.16\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement conda==23.9.0 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for conda==23.9.0\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h=================== bitsandbytes v0.48.2 ===================\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "  libc: glibc-2.35\n",
            "Python: 3.12.12\n",
            "PyTorch: 2.8.0+cu126\n",
            "  CUDA: 12.6\n",
            "  HIP: N/A\n",
            "  XPU: N/A\n",
            "Related packages:\n",
            "  accelerate: 1.11.0\n",
            "  diffusers: 0.35.2\n",
            "  numpy: 2.0.2\n",
            "  pip: 24.1.2\n",
            "  peft: 0.18.0\n",
            "  safetensors: 0.6.2\n",
            "  transformers: 4.57.1\n",
            "  triton: 3.4.0\n",
            "  trl: not found\n",
            "============================================================\n",
            "PyTorch settings found: CUDA_VERSION=126, Highest Compute Capability: (8, 0).\n",
            "Checking that the library is importable and CUDA is callable...\n",
            "SUCCESS!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fire --quiet\n"
      ],
      "metadata": {
        "id": "Gn7zZKmpcLXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2328ed89-360c-45c1-c4f8-612214fc2064"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"transformers>=4.46.0\" \"peft>=0.17.0\" \"accelerate>=0.33.0\" \"bitsandbytes>=0.45.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XwlSshIhOpc",
        "outputId": "5ba6a632-8c18-4fb1-b4a5-edc39513eaae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: peft>=0.17.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: accelerate>=0.33.0 in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: bitsandbytes>=0.45.0 in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft>=0.17.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft>=0.17.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46.0) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft>=0.17.0) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.46.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.46.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.46.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.46.0) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft>=0.17.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft>=0.17.0) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FederatedLLM\n",
        "!pwd\n",
        "!ls data_wiz/10 | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awrVsY9wSqu7",
        "outputId": "32616789-0d58-4e36-f87b-da6f880cfeb1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FederatedLLM\n",
            "/content/FederatedLLM\n",
            "local_training_0.json\n",
            "local_training_1.json\n",
            "local_training_2.json\n",
            "local_training_3.json\n",
            "local_training_4.json\n",
            "local_training_5.json\n",
            "local_training_6.json\n",
            "local_training_7.json\n",
            "local_training_8.json\n",
            "local_training_9.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff_len = 512\n",
        "def tokenize(prompt, add_eos_token=True):\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=cutoff_len,\n",
        "        padding=False,\n",
        "        return_tensors=None,\n",
        "    )\n",
        "    if (\n",
        "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
        "        and len(result[\"input_ids\"]) < cutoff_len\n",
        "        and add_eos_token\n",
        "    ):\n",
        "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
        "        result[\"attention_mask\"].append(1)\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "    if \"context\" in data_point:\n",
        "        full_prompt = prompter.generate_prompt(\n",
        "            data_point.get(\"instruction\", \"\"),\n",
        "            data_point.get(\"context\", \"\"),\n",
        "            data_point.get(\"response\", data_point.get(\"output\", \"\")),\n",
        "        )\n",
        "    else:\n",
        "        full_prompt = prompter.generate_prompt(\n",
        "            data_point.get(\"instruction\", \"\"),\n",
        "            data_point.get(\"input\", \"\"),\n",
        "            data_point.get(\"output\", \"\"),\n",
        "        )\n",
        "\n",
        "    tokenized_full_prompt = tokenize(full_prompt)\n",
        "    user_prompt = prompter.generate_prompt(\n",
        "        data_point.get(\"instruction\", \"\"),\n",
        "        data_point.get(\"input\", \"\")\n",
        "    )\n",
        "    tokenized_user_prompt = tokenize(user_prompt, add_eos_token=False)\n",
        "    user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
        "    tokenized_full_prompt[\"labels\"] = (\n",
        "        [-100] * user_prompt_len\n",
        "        + tokenized_full_prompt[\"labels\"][user_prompt_len:]\n",
        "    )\n",
        "    return tokenized_full_prompt"
      ],
      "metadata": {
        "id": "4UVI15xwb5F2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf lora_sim_roberta_rte/*\n"
      ],
      "metadata": {
        "id": "ZcmWcW4jaYg8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, math, copy, json, itertools, random, numpy as np, pandas as pd\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
        "                          Trainer, TrainingArguments, DataCollatorWithPadding)\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "@dataclass\n",
        "class ExpCfg:\n",
        "    model_name: str = \"roberta-base\"\n",
        "    task_name: str = \"rte\"\n",
        "    num_clients: int = 8\n",
        "    local_epochs: int = 2\n",
        "    per_device_batch: int = 16\n",
        "    lr: float = 2e-4\n",
        "    max_len: int = 256\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: float = 0.05\n",
        "    target_modules: tuple = (\"query\", \"value\")\n",
        "    hetero_mode: str = \"iid\"\n",
        "    outdir: str = \"./lora_sim_roberta_rte\"\n",
        "\n",
        "cfg = ExpCfg(\n",
        "    num_clients=8,\n",
        "    local_epochs=2,\n",
        "    hetero_mode=\"server_non_iid\",\n",
        ")\n",
        "\n",
        "os.makedirs(cfg.outdir, exist_ok=True)\n",
        "\n",
        "raw = load_dataset(\"glue\", cfg.task_name)\n",
        "tok = AutoTokenizer.from_pretrained(cfg.model_name, use_fast=True)\n",
        "\n",
        "def preprocess(batch):\n",
        "    return tok(batch[\"sentence1\"], batch[\"sentence2\"], truncation=True, max_length=cfg.max_len)\n",
        "\n",
        "encoded = raw.map(preprocess, batched=True)\n",
        "num_labels = raw[\"train\"].features[\"label\"].num_classes\n",
        "\n",
        "def split_clients(dataset, num_clients, mode=\"iid\", dirichlet_alpha=0.5):\n",
        "    labels = np.array(dataset[\"label\"])\n",
        "    n = len(labels)\n",
        "    idxs = np.arange(n)\n",
        "\n",
        "    if mode == \"iid\":\n",
        "        np.random.shuffle(idxs)\n",
        "        return np.array_split(idxs, num_clients)\n",
        "\n",
        "    classes = np.unique(labels)\n",
        "    class_indices = {c: np.where(labels == c)[0] for c in classes}\n",
        "    parts = [[] for _ in range(num_clients)]\n",
        "    alpha = dirichlet_alpha\n",
        "\n",
        "    for c in classes:\n",
        "        ci = class_indices[c]\n",
        "        np.random.shuffle(ci)\n",
        "        p = np.random.dirichlet([alpha] * num_clients)\n",
        "        splits = (np.cumsum(p) * len(ci)).astype(int)[:-1]\n",
        "        shards = np.split(ci, splits)\n",
        "        for k in range(num_clients):\n",
        "            parts[k].extend(shards[k].tolist())\n",
        "\n",
        "    parts = [np.array(p, dtype=int) for p in parts]\n",
        "    for k in range(num_clients):\n",
        "        np.random.shuffle(parts[k])\n",
        "    return parts\n",
        "\n",
        "\n",
        "if cfg.hetero_mode == \"iid\":\n",
        "    client_indices = split_clients(raw[\"train\"], cfg.num_clients, \"iid\")\n",
        "\n",
        "elif cfg.hetero_mode == \"moderate_non_iid\":\n",
        "    client_indices = split_clients(raw[\"train\"], cfg.num_clients, \"dir\", dirichlet_alpha=0.5)\n",
        "\n",
        "elif cfg.hetero_mode == \"server_non_iid\":\n",
        "    client_indices = split_clients(raw[\"train\"], cfg.num_clients, \"dir\", dirichlet_alpha=0.1)\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"hetero_mode must be ['iid','moderate_non_iid','server_non_iid']\")\n",
        "\n",
        "cols_to_keep = [\"input_ids\", \"attention_mask\", \"label\"]\n",
        "\n",
        "def make_subset(ds, indices):\n",
        "    return ds.select(indices).remove_columns([c for c in ds.column_names if c not in cols_to_keep])\n",
        "\n",
        "client_datasets = [make_subset(encoded[\"train\"], idxs) for idxs in client_indices]\n",
        "eval_ds = make_subset(encoded[\"validation\"], range(len(encoded[\"validation\"])))\n",
        "\n",
        "quant_ok = torch.cuda.is_available()\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(cfg.model_name, num_labels=num_labels)\n",
        "\n",
        "base_model = prepare_model_for_kbit_training(base_model)\n",
        "lora_cfg = LoraConfig(\n",
        "    r=cfg.lora_r, lora_alpha=cfg.lora_alpha, lora_dropout=cfg.lora_dropout,\n",
        "    target_modules=list(cfg.target_modules), bias=\"none\", task_type=\"SEQ_CLS\"\n",
        ")\n",
        "base_model = get_peft_model(base_model, lora_cfg)\n",
        "\n",
        "def train_one_client(client_id, train_ds):\n",
        "    if len(train_ds) == 0:\n",
        "        print(f\" Client {client_id} has 0 samples — skipping.\")\n",
        "        return None\n",
        "\n",
        "    model = copy.deepcopy(base_model)\n",
        "    args = TrainingArguments(\n",
        "        output_dir=os.path.join(cfg.outdir, f\"client_{client_id}\"),\n",
        "        num_train_epochs=cfg.local_epochs,\n",
        "        per_device_train_batch_size=cfg.per_device_batch,\n",
        "        per_device_eval_batch_size=cfg.per_device_batch,\n",
        "        learning_rate=cfg.lr,\n",
        "        logging_steps=20,\n",
        "        eval_strategy=\"no\",\n",
        "        save_strategy=\"no\",\n",
        "        report_to=[],\n",
        "        seed=SEED,\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        data_collator=DataCollatorWithPadding(tok),\n",
        "    )\n",
        "    trainer.train()\n",
        "    return model\n",
        "\n",
        "client_models = []\n",
        "for k in range(cfg.num_clients):\n",
        "    print(f\" Training client {k} with {len(client_datasets[k])} samples ...\")\n",
        "    m = train_one_client(k, client_datasets[k])\n",
        "    if m is not None:\n",
        "        client_models.append(m)\n",
        "\n",
        "def extract_lora_by_layer(model) -> Dict[str, Dict[int, torch.Tensor]]:\n",
        "    A_layers, B_layers = {}, {}\n",
        "    for n, p in model.named_parameters():\n",
        "        if \"lora_A\" in n or \"lora_B\" in n:\n",
        "            parts = n.split(\".\")\n",
        "            if \"layer\" not in parts:\n",
        "                continue\n",
        "            lid = int(parts[parts.index(\"layer\")+1])\n",
        "            if \"attention\" not in parts or not any(t in parts for t in [\"query\",\"value\"]):\n",
        "                continue\n",
        "            key = \"A\" if \"lora_A\" in n else \"B\"\n",
        "            vec = p.detach().cpu().flatten()\n",
        "            (A_layers if key==\"A\" else B_layers).setdefault(lid, []).append(vec)\n",
        "    return {\n",
        "        \"A\": {lid: torch.cat(vs) for lid, vs in A_layers.items()},\n",
        "        \"B\": {lid: torch.cat(vs) for lid, vs in B_layers.items()}\n",
        "    }\n",
        "\n",
        "client_loras = [extract_lora_by_layer(m) for m in client_models]\n",
        "all_layers = sorted(set().union(*[set(d[\"A\"].keys()) for d in client_loras]))\n",
        "\n",
        "def mean_pairwise_cosine(vectors):\n",
        "    if len(vectors) < 2: return float(\"nan\")\n",
        "    sims = []\n",
        "    for i,j in itertools.combinations(range(len(vectors)),2):\n",
        "        sims.append(F.cosine_similarity(vectors[i].unsqueeze(0), vectors[j].unsqueeze(0)).item())\n",
        "    return float(np.mean(sims))\n",
        "\n",
        "layer_stats = []\n",
        "for lid in all_layers:\n",
        "    A_vecs, B_vecs = [], []\n",
        "    for c in range(len(client_loras)):\n",
        "        if lid in client_loras[c][\"A\"]: A_vecs.append(client_loras[c][\"A\"][lid])\n",
        "        if lid in client_loras[c][\"B\"]: B_vecs.append(client_loras[c][\"B\"][lid])\n",
        "    layer_stats.append({\n",
        "        \"layer\": lid,\n",
        "        \"A\": mean_pairwise_cosine(A_vecs),\n",
        "        \"B\": mean_pairwise_cosine(B_vecs),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(layer_stats).sort_values(\"layer\")\n",
        "df.to_csv(os.path.join(cfg.outdir, f\"pairwise_cosine_{cfg.hetero_mode}.csv\"), index=False)\n",
        "print(df)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "x = np.arange(len(df))\n",
        "plt.bar(x-0.2, df[\"A\"], width=0.4, label=\"LoRA-A\")\n",
        "plt.bar(x+0.2, df[\"B\"], width=0.4, label=\"LoRA-B\")\n",
        "plt.xticks(x, [f\"L{int(l)}\" for l in df[\"layer\"]], rotation=0)\n",
        "plt.ylim(0,1.0); plt.grid(axis=\"y\", alpha=0.25)\n",
        "plt.title(f\"Mean pairwise cosine per layer | {cfg.hetero_mode}\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(cfg.outdir, f\"figure2_style_{cfg.hetero_mode}.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9bb3ed884a5f43d984a258683971da65",
            "48fe27ce952c42b1ac617d80da266503",
            "23d6d75233fe4bfab73d16bff1ce795d",
            "7dc94aa4ca474504ab0628936eed00d0",
            "efa1e6ce1deb4731b7b9703a302674ff",
            "03ee269ddaa64c0d9aa053ea99b346b1",
            "7be3013d451d4cb2bd0abf12b6be09f3",
            "9b38184c138d437f8ebaed9c89a01a23",
            "f2ea7a12df8c48c393c75df476667b14",
            "1db217e246144b6fbf508d2b443c7033",
            "2c5e152195fa4a109de0c57abbfa7bd6",
            "51a2dab6689f400cbd0ffa21ee78c063",
            "904d74328fa94dd9a5f059e9accc8450",
            "59eca621f49045798db2f6bbe19ce043",
            "b2e4d06d86124b9ba9af305ea96c7a7a",
            "de648ee9e05f479db05067b33c73505e",
            "84880dc055864f4d89790ee7e6467a67",
            "e51bbf4d3b674ddc9debff70fe356fae",
            "ee1cb93d4766429aa84856adf589eb49",
            "213199e89f444a4295987fe361cc2d0d",
            "c93fb5dff1854083802524b93b84d92f",
            "7b1af174db224dbfba9beca1086834cf",
            "1f9b02967c794e9b828e618cbd07a639",
            "c3a6accb53b84bc68c692614885ba9d2",
            "3c6448f1a24f4bf38d84d457333f83e4",
            "6fde40d02c0646b0b860d62b194adc3f",
            "19ac0c8627b44e3a8022662902b648fe",
            "60e0d19ca7c141da9f53d220dd35188e",
            "708a9200a23a446ea24854794ba33e38",
            "5d643035408743158291d03fd570823e",
            "fbff790471cc4fd1a2b22301e51a904a",
            "9fd1fa69cbc34c4a92c64622e560e54b",
            "9be506953834483aa31dccf4e9f8de3e"
          ]
        },
        "id": "b7QE66U_cGDF",
        "outputId": "040dd3d5-a6fe-4d2c-cc24-41e55c0f064e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2490 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bb3ed884a5f43d984a258683971da65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/277 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51a2dab6689f400cbd0ffa21ee78c063"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f9b02967c794e9b828e618cbd07a639"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧱 Training client 0 with 1218 samples ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='154' max='154' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [154/154 00:12, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.255200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.111900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.166100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.124700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.108700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.044600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.189000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧱 Training client 1 with 68 samples ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:00, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧱 Training client 2 with 429 samples ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 00:04, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.156200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧱 Training client 3 with 41 samples ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:00, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧱 Training client 4 with 724 samples ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [92/92 00:07, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.153600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.032600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.036500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧱 Training client 5 with 0 samples ...\n",
            "⚠️ Client 5 has 0 samples — skipping.\n",
            "🧱 Training client 6 with 0 samples ...\n",
            "⚠️ Client 6 has 0 samples — skipping.\n",
            "🧱 Training client 7 with 10 samples ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    layer         A         B\n",
            "0       0  0.996134  0.220990\n",
            "1       1  0.995385  0.293786\n",
            "2       2  0.994641  0.344198\n",
            "3       3  0.993981  0.320327\n",
            "4       4  0.994827  0.321950\n",
            "5       5  0.994467  0.312461\n",
            "6       6  0.994948  0.272046\n",
            "7       7  0.993883  0.298717\n",
            "8       8  0.994442  0.223420\n",
            "9       9  0.994314  0.282800\n",
            "10     10  0.993918  0.242529\n",
            "11     11  0.993415  0.219093\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, _ in client_models[0].named_parameters():\n",
        "    if \"lora\" in name.lower():\n",
        "        print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8ZLXjpZeGkq",
        "outputId": "fe6823ac-35b4-44d2-9a4d-ca9d038e97b0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_B.default.weight\n",
            "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_A.default.weight\n",
            "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_B.default.weight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_lora_matrix(model, layer_id, module=\"query\", AB=\"A\"):\n",
        "    \"\"\"\n",
        "    model:  client_models[k]\n",
        "    layer_id: int, [0-11]\n",
        "    module: \"query\" or \"value\"\n",
        "    AB: \"A\" or \"B\"\n",
        "    \"\"\"\n",
        "\n",
        "    target = (\n",
        "        f\"base_model.model.roberta.encoder.layer.{layer_id}\"\n",
        "        f\".attention.self.{module}.lora_{AB}.default.weight\"\n",
        "    )\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if name == target:\n",
        "            print(f\" Found LoRA-{AB}: {name}\")\n",
        "            print(\"Shape:\", param.shape)\n",
        "            print(\"Values:\")\n",
        "            print(param.detach().cpu().numpy())\n",
        "            return param.detach().cpu()\n",
        "\n",
        "    print(f\" Not found: {target}\")\n",
        "    print(\"\\n Available LoRA parameters include:\")\n",
        "    for name, _ in model.named_parameters():\n",
        "        if \"lora_\" in name:\n",
        "            print(name)\n",
        "\n",
        "    return None\n",
        "\n",
        "#show_lora_matrix(client_models[0], layer_id=3, module=\"query\", AB=\"B\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CSsuA4LZNnr",
        "outputId": "1a4b5d8e-f253-4185-d907-0936b42f06ce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Found LoRA-B: base_model.model.roberta.encoder.layer.3.attention.self.query.lora_B.default.weight\n",
            "Shape: torch.Size([768, 8])\n",
            "Values:\n",
            "[[ 2.8292751e-03 -9.7573975e-05  9.6176530e-04 ...  1.4129642e-03\n",
            "  -1.1296031e-03  1.0253303e-03]\n",
            " [-4.7945976e-04  3.5845004e-03 -8.2511501e-04 ...  6.9458911e-04\n",
            "   1.0743752e-03 -7.4610213e-04]\n",
            " [ 1.2248683e-03 -9.8120852e-04  8.5054926e-04 ...  2.5186748e-03\n",
            "  -2.2178395e-03  1.3236156e-03]\n",
            " ...\n",
            " [-1.7793538e-03  4.0558688e-03  1.2541711e-03 ...  8.7239727e-04\n",
            "   1.0005356e-03  9.8281249e-04]\n",
            " [-1.4681758e-03  3.1492298e-06 -2.0216133e-03 ... -1.9872915e-03\n",
            "   3.6490557e-03 -4.5260967e-05]\n",
            " [-7.8870717e-04  4.6477618e-04 -5.3489380e-06 ... -1.4880947e-04\n",
            "   3.2552256e-04  9.3381846e-04]]\n",
            "✔ Found LoRA-B: base_model.model.roberta.encoder.layer.3.attention.self.query.lora_B.default.weight\n",
            "Shape: torch.Size([768, 8])\n",
            "Values:\n",
            "[[ 1.06600448e-04 -3.87340871e-04 -8.93647593e-05 ... -2.88129610e-04\n",
            "   3.40560102e-04  2.99337771e-05]\n",
            " [-2.89555930e-04  2.34843465e-04 -1.64938887e-04 ...  1.75923851e-04\n",
            "   1.91188854e-04 -1.43226862e-04]\n",
            " [ 3.12955854e-05 -1.84061300e-05 -2.25814598e-04 ...  2.41628732e-04\n",
            "   9.07354261e-05 -1.14972456e-04]\n",
            " ...\n",
            " [-4.11895802e-04  9.11175739e-04 -2.57851847e-04 ... -4.52220644e-04\n",
            "   2.14813845e-05 -5.70731296e-04]\n",
            " [-1.40339194e-04 -5.02088340e-04 -7.80197617e-04 ... -6.59716723e-04\n",
            "   3.46190529e-04 -5.70544798e-04]\n",
            " [ 9.30905226e-04  6.77356511e-05  2.34859719e-04 ...  9.02681844e-04\n",
            "  -1.70903761e-04  3.76780983e-04]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0660e-04, -3.8734e-04, -8.9365e-05,  ..., -2.8813e-04,\n",
              "          3.4056e-04,  2.9934e-05],\n",
              "        [-2.8956e-04,  2.3484e-04, -1.6494e-04,  ...,  1.7592e-04,\n",
              "          1.9119e-04, -1.4323e-04],\n",
              "        [ 3.1296e-05, -1.8406e-05, -2.2581e-04,  ...,  2.4163e-04,\n",
              "          9.0735e-05, -1.1497e-04],\n",
              "        ...,\n",
              "        [-4.1190e-04,  9.1118e-04, -2.5785e-04,  ..., -4.5222e-04,\n",
              "          2.1481e-05, -5.7073e-04],\n",
              "        [-1.4034e-04, -5.0209e-04, -7.8020e-04,  ..., -6.5972e-04,\n",
              "          3.4619e-04, -5.7054e-04],\n",
              "        [ 9.3091e-04,  6.7736e-05,  2.3486e-04,  ...,  9.0268e-04,\n",
              "         -1.7090e-04,  3.7678e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FederatedLLM\n",
        "\n",
        "!python main.py --mode full_sa \\\n",
        "    --num_communication_rounds 3 \\\n",
        "    --output_dir ./runs/warmup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q9FzYqHTg4bf",
        "outputId": "9df9329e-31dd-4373-afaf-42cfc1e6ca4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FederatedLLM\n",
            "2025-11-14 18:16:55.432612: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-14 18:16:55.450283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763144215.471431    3426 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763144215.477876    3426 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763144215.494836    3426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763144215.494863    3426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763144215.494866    3426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763144215.494869    3426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-14 18:16:55.499690: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "🚀 FL + LoRA starting, mode=full_sa\n",
            "📂 Auto-selected data folder: ./data_wiz/10\n",
            "📦 Using 10 clients\n",
            "config.json: 100% 608/608 [00:00<00:00, 3.32MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors: 100% 2.20G/2.20G [00:03<00:00, 711MB/s] \n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 1.07MB/s]\n",
            "tokenizer_config.json: 1.29kB [00:00, 3.17MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 1.79MB/s]\n",
            "tokenizer.json: 1.84MB [00:00, 110MB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 4.28MB/s]\n",
            "🚀 Starting federated rounds...\n",
            "  0% 0/3 [00:00<?, ?it/s]\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train split: 6999 examples [00:00, 28752.39 examples/s]\n",
            "\n",
            "Map:   0% 0/6999 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:   1% 70/6999 [00:00<00:10, 686.63 examples/s]\u001b[A\n",
            "Map:   2% 141/6999 [00:00<00:09, 690.05 examples/s]\u001b[A\n",
            "Map:   3% 214/6999 [00:00<00:09, 706.41 examples/s]\u001b[A\n",
            "Map:   4% 296/6999 [00:00<00:09, 742.14 examples/s]\u001b[A\n",
            "Map:   5% 371/6999 [00:00<00:08, 736.58 examples/s]\u001b[A\n",
            "Map:   7% 461/6999 [00:00<00:09, 669.98 examples/s]\u001b[A\n",
            "Map:   8% 565/6999 [00:00<00:09, 675.18 examples/s]\u001b[A\n",
            "Map:   9% 644/6999 [00:00<00:09, 704.43 examples/s]\u001b[A\n",
            "Map:  10% 725/6999 [00:01<00:08, 712.03 examples/s]\u001b[A\n",
            "Map:  12% 805/6999 [00:01<00:08, 735.35 examples/s]\u001b[A\n",
            "Map:  13% 883/6999 [00:01<00:08, 741.66 examples/s]\u001b[A\n",
            "Map:  14% 1000/6999 [00:01<00:11, 527.69 examples/s]\u001b[A\n",
            "Map:  15% 1072/6999 [00:01<00:10, 559.25 examples/s]\u001b[A\n",
            "Map:  16% 1146/6999 [00:01<00:09, 595.56 examples/s]\u001b[A\n",
            "Map:  18% 1250/6999 [00:01<00:09, 622.61 examples/s]\u001b[A\n",
            "Map:  19% 1325/6999 [00:02<00:08, 649.56 examples/s]\u001b[A\n",
            "Map:  20% 1402/6999 [00:02<00:08, 676.33 examples/s]\u001b[A\n",
            "Map:  21% 1474/6999 [00:02<00:08, 678.16 examples/s]\u001b[A\n",
            "Map:  22% 1549/6999 [00:02<00:07, 696.17 examples/s]\u001b[A\n",
            "Map:  23% 1624/6999 [00:02<00:07, 705.99 examples/s]\u001b[A\n",
            "Map:  24% 1697/6999 [00:02<00:07, 710.24 examples/s]\u001b[A\n",
            "Map:  25% 1776/6999 [00:02<00:07, 731.14 examples/s]\u001b[A\n",
            "Map:  27% 1882/6999 [00:02<00:07, 717.83 examples/s]\u001b[A\n",
            "Map:  28% 1963/6999 [00:02<00:06, 740.12 examples/s]\u001b[A\n",
            "Map:  30% 2073/6999 [00:03<00:09, 526.28 examples/s]\u001b[A\n",
            "Map:  31% 2144/6999 [00:03<00:08, 561.69 examples/s]\u001b[A\n",
            "Map:  32% 2218/6999 [00:03<00:07, 598.89 examples/s]\u001b[A\n",
            "Map:  33% 2296/6999 [00:03<00:07, 638.27 examples/s]\u001b[A\n",
            "Map:  34% 2377/6999 [00:03<00:06, 680.31 examples/s]\u001b[A\n",
            "Map:  35% 2453/6999 [00:03<00:06, 699.22 examples/s]\u001b[A\n",
            "Map:  37% 2566/6999 [00:03<00:06, 709.92 examples/s]\u001b[A\n",
            "Map:  38% 2675/6999 [00:04<00:06, 708.95 examples/s]\u001b[A\n",
            "Map:  39% 2755/6999 [00:04<00:05, 729.11 examples/s]\u001b[A\n",
            "Map:  40% 2830/6999 [00:04<00:05, 731.39 examples/s]\u001b[A\n",
            "Map:  42% 2927/6999 [00:04<00:05, 697.18 examples/s]\u001b[A\n",
            "Map:  43% 3000/6999 [00:04<00:07, 506.58 examples/s]\u001b[A\n",
            "Map:  44% 3076/6999 [00:04<00:07, 558.12 examples/s]\u001b[A\n",
            "Map:  45% 3153/6999 [00:04<00:06, 603.17 examples/s]\u001b[A\n",
            "Map:  46% 3223/6999 [00:04<00:06, 625.77 examples/s]\u001b[A\n",
            "Map:  47% 3294/6999 [00:05<00:05, 646.37 examples/s]\u001b[A\n",
            "Map:  48% 3371/6999 [00:05<00:05, 679.07 examples/s]\u001b[A\n",
            "Map:  49% 3453/6999 [00:05<00:04, 715.79 examples/s]\u001b[A\n",
            "Map:  51% 3565/6999 [00:05<00:04, 721.94 examples/s]\u001b[A\n",
            "Map:  52% 3643/6999 [00:05<00:04, 736.03 examples/s]\u001b[A\n",
            "Map:  54% 3755/6999 [00:05<00:04, 733.86 examples/s]\u001b[A\n",
            "Map:  55% 3865/6999 [00:05<00:04, 728.39 examples/s]\u001b[A\n",
            "Map:  56% 3943/6999 [00:05<00:04, 736.13 examples/s]\u001b[A\n",
            "Map:  58% 4032/6999 [00:06<00:05, 525.74 examples/s]\u001b[A\n",
            "Map:  59% 4109/6999 [00:06<00:05, 572.02 examples/s]\u001b[A\n",
            "Map:  60% 4177/6999 [00:06<00:04, 593.77 examples/s]\u001b[A\n",
            "Map:  61% 4251/6999 [00:06<00:04, 627.30 examples/s]\u001b[A\n",
            "Map:  62% 4328/6999 [00:06<00:04, 660.66 examples/s]\u001b[A\n",
            "Map:  63% 4405/6999 [00:06<00:03, 686.51 examples/s]\u001b[A\n",
            "Map:  64% 4479/6999 [00:06<00:03, 698.69 examples/s]\u001b[A\n",
            "Map:  65% 4559/6999 [00:06<00:03, 722.83 examples/s]\u001b[A\n",
            "Map:  67% 4672/6999 [00:07<00:03, 730.50 examples/s]\u001b[A\n",
            "Map:  68% 4776/6999 [00:07<00:03, 713.98 examples/s]\u001b[A\n",
            "Map:  70% 4883/6999 [00:07<00:02, 710.34 examples/s]\u001b[A\n",
            "Map:  71% 4960/6999 [00:07<00:02, 723.10 examples/s]\u001b[A\n",
            "Map:  72% 5039/6999 [00:07<00:03, 520.11 examples/s]\u001b[A\n",
            "Map:  73% 5114/6999 [00:07<00:03, 566.06 examples/s]\u001b[A\n",
            "Map:  74% 5188/6999 [00:07<00:03, 602.71 examples/s]\u001b[A\n",
            "Map:  75% 5262/6999 [00:08<00:02, 634.31 examples/s]\u001b[A\n",
            "Map:  76% 5334/6999 [00:08<00:02, 652.52 examples/s]\u001b[A\n",
            "Map:  78% 5446/6999 [00:08<00:02, 683.09 examples/s]\u001b[A\n",
            "Map:  79% 5518/6999 [00:08<00:02, 690.50 examples/s]\u001b[A\n",
            "Map:  80% 5589/6999 [00:08<00:02, 693.95 examples/s]\u001b[A\n",
            "Map:  81% 5680/6999 [00:08<00:01, 749.64 examples/s]\u001b[A\n",
            "Map:  83% 5788/6999 [00:08<00:01, 737.43 examples/s]\u001b[A\n",
            "Map:  84% 5892/6999 [00:08<00:01, 718.34 examples/s]\u001b[A\n",
            "Map:  85% 5971/6999 [00:08<00:01, 732.71 examples/s]\u001b[A\n",
            "Map:  87% 6076/6999 [00:09<00:01, 535.94 examples/s]\u001b[A\n",
            "Map:  88% 6159/6999 [00:09<00:01, 591.32 examples/s]\u001b[A\n",
            "Map:  89% 6241/6999 [00:09<00:01, 638.30 examples/s]\u001b[A\n",
            "Map:  90% 6324/6999 [00:09<00:00, 680.51 examples/s]\u001b[A\n",
            "Map:  91% 6399/6999 [00:09<00:00, 694.67 examples/s]\u001b[A\n",
            "Map:  93% 6477/6999 [00:09<00:00, 715.76 examples/s]\u001b[A\n",
            "Map:  94% 6585/6999 [00:09<00:00, 713.30 examples/s]\u001b[A\n",
            "Map:  95% 6670/6999 [00:10<00:00, 744.97 examples/s]\u001b[A\n",
            "Map:  96% 6749/6999 [00:10<00:00, 755.87 examples/s]\u001b[A\n",
            "Map:  98% 6828/6999 [00:10<00:00, 760.19 examples/s]\u001b[A\n",
            "Map: 100% 6999/6999 [00:10<00:00, 655.30 examples/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/FederatedLLM/wandb/offline-run-20251114_181748-if1n1905\u001b[0m\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "                         \n",
            "\u001b[A{'loss': 1.2255, 'grad_norm': 0.4164530038833618, 'learning_rate': 0.0003, 'epoch': 0.02}\n",
            "  0% 0/3 [00:49<?, ?it/s]\n",
            "  2% 1/55 [00:12<11:30, 12.79s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.2306, 'grad_norm': 0.4130101799964905, 'learning_rate': 0.0002945454545454545, 'epoch': 0.04}\n",
            "  0% 0/3 [01:01<?, ?it/s]\n",
            "  4% 2/55 [00:24<10:38, 12.04s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1387, 'grad_norm': 0.4372333586215973, 'learning_rate': 0.00028909090909090904, 'epoch': 0.05}\n",
            "  0% 0/3 [01:12<?, ?it/s]\n",
            "  5% 3/55 [00:35<10:13, 11.80s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1516, 'grad_norm': 0.3632042109966278, 'learning_rate': 0.0002836363636363636, 'epoch': 0.07}\n",
            "  0% 0/3 [01:24<?, ?it/s]\n",
            "  7% 4/55 [00:47<09:55, 11.68s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1408, 'grad_norm': 0.3499593138694763, 'learning_rate': 0.00027818181818181815, 'epoch': 0.09}\n",
            "  0% 0/3 [01:35<?, ?it/s]\n",
            "  9% 5/55 [00:58<09:40, 11.61s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.116, 'grad_norm': 0.3295401632785797, 'learning_rate': 0.0002727272727272727, 'epoch': 0.11}\n",
            "  0% 0/3 [01:47<?, ?it/s]\n",
            " 11% 6/55 [01:10<09:27, 11.58s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.07, 'grad_norm': 0.40816107392311096, 'learning_rate': 0.0002672727272727272, 'epoch': 0.13}\n",
            "  0% 0/3 [01:58<?, ?it/s]\n",
            " 13% 7/55 [01:21<09:14, 11.56s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.057, 'grad_norm': 0.5719820261001587, 'learning_rate': 0.0002618181818181818, 'epoch': 0.15}\n",
            "  0% 0/3 [02:10<?, ?it/s]\n",
            " 15% 8/55 [01:33<09:02, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0476, 'grad_norm': 0.4370338022708893, 'learning_rate': 0.00025636363636363633, 'epoch': 0.16}\n",
            "  0% 0/3 [02:21<?, ?it/s]\n",
            " 16% 9/55 [01:44<08:50, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0696, 'grad_norm': 0.41450899839401245, 'learning_rate': 0.00025090909090909086, 'epoch': 0.18}\n",
            "  0% 0/3 [02:33<?, ?it/s]\n",
            " 18% 10/55 [01:56<08:38, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0214, 'grad_norm': 0.34457290172576904, 'learning_rate': 0.00024545454545454545, 'epoch': 0.2}\n",
            "  0% 0/3 [02:44<?, ?it/s]\n",
            " 20% 11/55 [02:07<08:26, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.987, 'grad_norm': 0.29441094398498535, 'learning_rate': 0.00023999999999999998, 'epoch': 0.22}\n",
            "  0% 0/3 [02:56<?, ?it/s]\n",
            " 22% 12/55 [02:19<08:15, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9776, 'grad_norm': 0.27342158555984497, 'learning_rate': 0.00023454545454545454, 'epoch': 0.24}\n",
            "  0% 0/3 [03:07<?, ?it/s]\n",
            " 24% 13/55 [02:30<08:03, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9754, 'grad_norm': 0.281110018491745, 'learning_rate': 0.00022909090909090907, 'epoch': 0.26}\n",
            "  0% 0/3 [03:19<?, ?it/s]\n",
            " 25% 14/55 [02:42<07:52, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9332, 'grad_norm': 0.24280330538749695, 'learning_rate': 0.00022363636363636363, 'epoch': 0.27}\n",
            "  0% 0/3 [03:30<?, ?it/s]\n",
            " 27% 15/55 [02:53<07:40, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0018, 'grad_norm': 0.25114038586616516, 'learning_rate': 0.00021818181818181816, 'epoch': 0.29}\n",
            "  0% 0/3 [03:42<?, ?it/s]\n",
            " 29% 16/55 [03:05<07:29, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9511, 'grad_norm': 0.23786339163780212, 'learning_rate': 0.00021272727272727272, 'epoch': 0.31}\n",
            "  0% 0/3 [03:53<?, ?it/s]\n",
            " 31% 17/55 [03:17<07:17, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9538, 'grad_norm': 0.2105587124824524, 'learning_rate': 0.00020727272727272725, 'epoch': 0.33}\n",
            "  0% 0/3 [04:05<?, ?it/s]\n",
            " 33% 18/55 [03:28<07:06, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9336, 'grad_norm': 0.19324198365211487, 'learning_rate': 0.0002018181818181818, 'epoch': 0.35}\n",
            "  0% 0/3 [04:16<?, ?it/s]\n",
            " 35% 19/55 [03:40<06:54, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9744, 'grad_norm': 0.1895952820777893, 'learning_rate': 0.00019636363636363634, 'epoch': 0.37}\n",
            "  0% 0/3 [04:28<?, ?it/s]\n",
            " 36% 20/55 [03:51<06:43, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9448, 'grad_norm': 0.16530606150627136, 'learning_rate': 0.0001909090909090909, 'epoch': 0.38}\n",
            "  0% 0/3 [04:39<?, ?it/s]\n",
            " 38% 21/55 [04:03<06:31, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9061, 'grad_norm': 0.15653298795223236, 'learning_rate': 0.00018545454545454543, 'epoch': 0.4}\n",
            "  0% 0/3 [04:51<?, ?it/s]\n",
            " 40% 22/55 [04:14<06:19, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9355, 'grad_norm': 0.15976376831531525, 'learning_rate': 0.00017999999999999998, 'epoch': 0.42}\n",
            "  0% 0/3 [05:02<?, ?it/s]\n",
            " 42% 23/55 [04:26<06:08, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9784, 'grad_norm': 0.14286008477210999, 'learning_rate': 0.00017454545454545452, 'epoch': 0.44}\n",
            "  0% 0/3 [05:14<?, ?it/s]\n",
            " 44% 24/55 [04:37<05:56, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9388, 'grad_norm': 0.15444190800189972, 'learning_rate': 0.00016909090909090907, 'epoch': 0.46}\n",
            "  0% 0/3 [05:25<?, ?it/s]\n",
            " 45% 25/55 [04:49<05:45, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9727, 'grad_norm': 0.15681709349155426, 'learning_rate': 0.0001636363636363636, 'epoch': 0.47}\n",
            "  0% 0/3 [05:37<?, ?it/s]\n",
            " 47% 26/55 [05:00<05:33, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.972, 'grad_norm': 0.1457923799753189, 'learning_rate': 0.00015818181818181816, 'epoch': 0.49}\n",
            "  0% 0/3 [05:48<?, ?it/s]\n",
            " 49% 27/55 [05:12<05:22, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9756, 'grad_norm': 0.15272489190101624, 'learning_rate': 0.0001527272727272727, 'epoch': 0.51}\n",
            "  0% 0/3 [06:00<?, ?it/s]\n",
            " 51% 28/55 [05:23<05:10, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9252, 'grad_norm': 0.13293582201004028, 'learning_rate': 0.00014727272727272725, 'epoch': 0.53}\n",
            "  0% 0/3 [06:11<?, ?it/s]\n",
            " 53% 29/55 [05:35<04:59, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9284, 'grad_norm': 0.12920399010181427, 'learning_rate': 0.0001418181818181818, 'epoch': 0.55}\n",
            "  0% 0/3 [06:23<?, ?it/s]\n",
            " 55% 30/55 [05:46<04:47, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9258, 'grad_norm': 0.12368094176054001, 'learning_rate': 0.00013636363636363634, 'epoch': 0.57}\n",
            "  0% 0/3 [06:34<?, ?it/s]\n",
            " 56% 31/55 [05:58<04:36, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9592, 'grad_norm': 0.1309899091720581, 'learning_rate': 0.0001309090909090909, 'epoch': 0.58}\n",
            "  0% 0/3 [06:46<?, ?it/s]\n",
            " 58% 32/55 [06:09<04:24, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9383, 'grad_norm': 0.12457097321748734, 'learning_rate': 0.00012545454545454543, 'epoch': 0.6}\n",
            "  0% 0/3 [06:57<?, ?it/s]\n",
            " 60% 33/55 [06:21<04:13, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9146, 'grad_norm': 0.14050008356571198, 'learning_rate': 0.00011999999999999999, 'epoch': 0.62}\n",
            "  0% 0/3 [07:09<?, ?it/s]\n",
            " 62% 34/55 [06:32<04:01, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9422, 'grad_norm': 0.12084721028804779, 'learning_rate': 0.00011454545454545453, 'epoch': 0.64}\n",
            "  0% 0/3 [07:20<?, ?it/s]\n",
            " 64% 35/55 [06:44<03:50, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9063, 'grad_norm': 0.12636232376098633, 'learning_rate': 0.00010909090909090908, 'epoch': 0.66}\n",
            "  0% 0/3 [07:32<?, ?it/s]\n",
            " 65% 36/55 [06:55<03:38, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9465, 'grad_norm': 0.1211947649717331, 'learning_rate': 0.00010363636363636362, 'epoch': 0.68}\n",
            "  0% 0/3 [07:44<?, ?it/s]\n",
            " 67% 37/55 [07:07<03:27, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9499, 'grad_norm': 0.12737645208835602, 'learning_rate': 9.818181818181817e-05, 'epoch': 0.69}\n",
            "  0% 0/3 [07:55<?, ?it/s]\n",
            " 69% 38/55 [07:18<03:15, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9297, 'grad_norm': 0.12283533811569214, 'learning_rate': 9.272727272727271e-05, 'epoch': 0.71}\n",
            "  0% 0/3 [08:07<?, ?it/s]\n",
            " 71% 39/55 [07:30<03:04, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9362, 'grad_norm': 0.12041893601417542, 'learning_rate': 8.727272727272726e-05, 'epoch': 0.73}\n",
            "  0% 0/3 [08:18<?, ?it/s]\n",
            " 73% 40/55 [07:41<02:52, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9273, 'grad_norm': 0.1152583435177803, 'learning_rate': 8.18181818181818e-05, 'epoch': 0.75}\n",
            "  0% 0/3 [08:30<?, ?it/s]\n",
            " 75% 41/55 [07:53<02:41, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9275, 'grad_norm': 0.12070799618959427, 'learning_rate': 7.636363636363635e-05, 'epoch': 0.77}\n",
            "  0% 0/3 [08:41<?, ?it/s]\n",
            " 76% 42/55 [08:04<02:29, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9186, 'grad_norm': 0.12672266364097595, 'learning_rate': 7.09090909090909e-05, 'epoch': 0.79}\n",
            "  0% 0/3 [08:53<?, ?it/s]\n",
            " 78% 43/55 [08:16<02:18, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9402, 'grad_norm': 0.12222429364919662, 'learning_rate': 6.545454545454545e-05, 'epoch': 0.8}\n",
            "  0% 0/3 [09:04<?, ?it/s]\n",
            " 80% 44/55 [08:27<02:06, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.943, 'grad_norm': 0.11442508548498154, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.82}\n",
            "  0% 0/3 [09:16<?, ?it/s]\n",
            " 82% 45/55 [08:39<01:55, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9197, 'grad_norm': 0.11807242780923843, 'learning_rate': 5.454545454545454e-05, 'epoch': 0.84}\n",
            "  0% 0/3 [09:27<?, ?it/s]\n",
            " 84% 46/55 [08:50<01:43, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9333, 'grad_norm': 0.11616598069667816, 'learning_rate': 4.9090909090909084e-05, 'epoch': 0.86}\n",
            "  0% 0/3 [09:39<?, ?it/s]\n",
            " 85% 47/55 [09:02<01:32, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9481, 'grad_norm': 0.1121475100517273, 'learning_rate': 4.363636363636363e-05, 'epoch': 0.88}\n",
            "  0% 0/3 [09:50<?, ?it/s]\n",
            " 87% 48/55 [09:14<01:20, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9482, 'grad_norm': 0.11453305929899216, 'learning_rate': 3.8181818181818174e-05, 'epoch': 0.89}\n",
            "  0% 0/3 [10:02<?, ?it/s]\n",
            " 89% 49/55 [09:25<01:09, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.914, 'grad_norm': 0.11199765652418137, 'learning_rate': 3.2727272727272725e-05, 'epoch': 0.91}\n",
            "  0% 0/3 [10:13<?, ?it/s]\n",
            " 91% 50/55 [09:37<00:57, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9487, 'grad_norm': 0.11732124537229538, 'learning_rate': 2.727272727272727e-05, 'epoch': 0.93}\n",
            "  0% 0/3 [10:25<?, ?it/s]\n",
            " 93% 51/55 [09:48<00:46, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9116, 'grad_norm': 0.11342472583055496, 'learning_rate': 2.1818181818181814e-05, 'epoch': 0.95}\n",
            "  0% 0/3 [10:36<?, ?it/s]\n",
            " 95% 52/55 [10:00<00:34, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9301, 'grad_norm': 0.11301086843013763, 'learning_rate': 1.6363636363636363e-05, 'epoch': 0.97}\n",
            "  0% 0/3 [10:48<?, ?it/s]\n",
            " 96% 53/55 [10:11<00:23, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8942, 'grad_norm': 0.11348437517881393, 'learning_rate': 1.0909090909090907e-05, 'epoch': 0.99}\n",
            "  0% 0/3 [10:59<?, ?it/s]\n",
            " 98% 54/55 [10:23<00:11, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9725, 'grad_norm': 0.14476239681243896, 'learning_rate': 5.454545454545454e-06, 'epoch': 1.0}\n",
            "  0% 0/3 [11:07<?, ?it/s]\n",
            "                         \n",
            "\u001b[A{'train_runtime': 639.5805, 'train_samples_per_second': 10.943, 'train_steps_per_second': 0.086, 'train_loss': 0.9774569717320529, 'epoch': 1.0}\n",
            "  0% 0/3 [11:08<?, ?it/s]\n",
            "100% 55/55 [10:31<00:00, 11.49s/it]\n",
            "\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train split: 6999 examples [00:00, 32440.61 examples/s]\n",
            "\n",
            "Map:   0% 0/6999 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:   1% 68/6999 [00:00<00:10, 668.04 examples/s]\u001b[A\n",
            "Map:   2% 145/6999 [00:00<00:09, 722.84 examples/s]\u001b[A\n",
            "Map:   3% 243/6999 [00:00<00:09, 680.25 examples/s]\u001b[A\n",
            "Map:   4% 313/6999 [00:00<00:09, 683.92 examples/s]\u001b[A\n",
            "Map:   6% 386/6999 [00:00<00:09, 696.70 examples/s]\u001b[A\n",
            "Map:   7% 461/6999 [00:00<00:09, 708.93 examples/s]\u001b[A\n",
            "Map:   8% 537/6999 [00:00<00:08, 721.77 examples/s]\u001b[A\n",
            "Map:   9% 612/6999 [00:00<00:08, 726.90 examples/s]\u001b[A\n",
            "Map:  10% 688/6999 [00:00<00:08, 730.11 examples/s]\u001b[A\n",
            "Map:  11% 767/6999 [00:01<00:08, 744.01 examples/s]\u001b[A\n",
            "Map:  12% 851/6999 [00:01<00:07, 769.09 examples/s]\u001b[A\n",
            "Map:  14% 963/6999 [00:01<00:07, 757.17 examples/s]\u001b[A\n",
            "Map:  15% 1042/6999 [00:01<00:11, 533.95 examples/s]\u001b[A\n",
            "Map:  16% 1119/6999 [00:01<00:10, 582.18 examples/s]\u001b[A\n",
            "Map:  17% 1193/6999 [00:01<00:09, 617.25 examples/s]\u001b[A\n",
            "Map:  18% 1271/6999 [00:01<00:08, 649.37 examples/s]\u001b[A\n",
            "Map:  19% 1350/6999 [00:01<00:08, 683.28 examples/s]\u001b[A\n",
            "Map:  21% 1457/6999 [00:02<00:08, 686.35 examples/s]\u001b[A\n",
            "Map:  22% 1565/6999 [00:02<00:07, 691.87 examples/s]\u001b[A\n",
            "Map:  23% 1642/6999 [00:02<00:07, 707.52 examples/s]\u001b[A\n",
            "Map:  25% 1721/6999 [00:02<00:07, 726.54 examples/s]\u001b[A\n",
            "Map:  26% 1797/6999 [00:02<00:07, 733.67 examples/s]\u001b[A\n",
            "Map:  27% 1878/6999 [00:02<00:06, 753.34 examples/s]\u001b[A\n",
            "Map:  28% 1982/6999 [00:02<00:06, 726.80 examples/s]\u001b[A\n",
            "Map:  30% 2068/6999 [00:03<00:09, 515.68 examples/s]\u001b[A\n",
            "Map:  31% 2150/6999 [00:03<00:08, 575.08 examples/s]\u001b[A\n",
            "Map:  32% 2227/6999 [00:03<00:07, 615.79 examples/s]\u001b[A\n",
            "Map:  33% 2305/6999 [00:03<00:07, 653.61 examples/s]\u001b[A\n",
            "Map:  34% 2405/6999 [00:03<00:07, 655.38 examples/s]\u001b[A\n",
            "Map:  35% 2475/6999 [00:03<00:06, 665.28 examples/s]\u001b[A\n",
            "Map:  36% 2551/6999 [00:03<00:06, 687.09 examples/s]\u001b[A\n",
            "Map:  38% 2657/6999 [00:03<00:06, 686.73 examples/s]\u001b[A\n",
            "Map:  39% 2731/6999 [00:04<00:06, 695.76 examples/s]\u001b[A\n",
            "Map:  40% 2805/6999 [00:04<00:05, 706.22 examples/s]\u001b[A\n",
            "Map:  41% 2885/6999 [00:04<00:06, 629.24 examples/s]\u001b[A\n",
            "Map:  42% 2959/6999 [00:04<00:06, 656.75 examples/s]\u001b[A\n",
            "Map:  43% 3035/6999 [00:04<00:08, 469.81 examples/s]\u001b[A\n",
            "Map:  44% 3108/6999 [00:04<00:07, 520.82 examples/s]\u001b[A\n",
            "Map:  45% 3184/6999 [00:04<00:06, 571.70 examples/s]\u001b[A\n",
            "Map:  47% 3262/6999 [00:04<00:06, 621.41 examples/s]\u001b[A\n",
            "Map:  48% 3339/6999 [00:05<00:05, 657.13 examples/s]\u001b[A\n",
            "Map:  49% 3413/6999 [00:05<00:05, 675.83 examples/s]\u001b[A\n",
            "Map:  50% 3514/6999 [00:05<00:05, 673.03 examples/s]\u001b[A\n",
            "Map:  51% 3586/6999 [00:05<00:05, 682.26 examples/s]\u001b[A\n",
            "Map:  52% 3671/6999 [00:05<00:04, 724.18 examples/s]\u001b[A\n",
            "Map:  54% 3748/6999 [00:05<00:04, 735.51 examples/s]\u001b[A\n",
            "Map:  55% 3824/6999 [00:05<00:04, 738.74 examples/s]\u001b[A\n",
            "Map:  56% 3909/6999 [00:05<00:04, 767.43 examples/s]\u001b[A\n",
            "Map:  57% 4000/6999 [00:06<00:05, 528.31 examples/s]\u001b[A\n",
            "Map:  58% 4074/6999 [00:06<00:05, 572.95 examples/s]\u001b[A\n",
            "Map:  59% 4155/6999 [00:06<00:04, 626.73 examples/s]\u001b[A\n",
            "Map:  61% 4260/6999 [00:06<00:04, 646.45 examples/s]\u001b[A\n",
            "Map:  62% 4370/6999 [00:06<00:03, 668.90 examples/s]\u001b[A\n",
            "Map:  63% 4443/6999 [00:06<00:03, 682.61 examples/s]\u001b[A\n",
            "Map:  65% 4516/6999 [00:06<00:03, 691.86 examples/s]\u001b[A\n",
            "Map:  66% 4590/6999 [00:06<00:03, 704.11 examples/s]\u001b[A\n",
            "Map:  67% 4670/6999 [00:07<00:03, 727.35 examples/s]\u001b[A\n",
            "Map:  68% 4752/6999 [00:07<00:02, 752.19 examples/s]\u001b[A\n",
            "Map:  69% 4829/6999 [00:07<00:02, 750.63 examples/s]\u001b[A\n",
            "Map:  70% 4909/6999 [00:07<00:02, 761.79 examples/s]\u001b[A\n",
            "Map:  71% 5000/6999 [00:07<00:03, 528.03 examples/s]\u001b[A\n",
            "Map:  72% 5070/6999 [00:07<00:03, 563.79 examples/s]\u001b[A\n",
            "Map:  73% 5144/6999 [00:07<00:03, 600.73 examples/s]\u001b[A\n",
            "Map:  74% 5213/6999 [00:07<00:02, 620.23 examples/s]\u001b[A\n",
            "Map:  75% 5282/6999 [00:08<00:02, 634.00 examples/s]\u001b[A\n",
            "Map:  77% 5363/6999 [00:08<00:02, 678.31 examples/s]\u001b[A\n",
            "Map:  78% 5440/6999 [00:08<00:02, 698.22 examples/s]\u001b[A\n",
            "Map:  79% 5522/6999 [00:08<00:02, 728.93 examples/s]\u001b[A\n",
            "Map:  80% 5597/6999 [00:08<00:01, 733.60 examples/s]\u001b[A\n",
            "Map:  81% 5672/6999 [00:08<00:01, 735.93 examples/s]\u001b[A\n",
            "Map:  82% 5751/6999 [00:08<00:01, 749.72 examples/s]\u001b[A\n",
            "Map:  84% 5848/6999 [00:08<00:01, 705.34 examples/s]\u001b[A\n",
            "Map:  85% 5928/6999 [00:08<00:01, 729.72 examples/s]\u001b[A\n",
            "Map:  86% 6034/6999 [00:09<00:01, 523.04 examples/s]\u001b[A\n",
            "Map:  87% 6106/6999 [00:09<00:01, 559.91 examples/s]\u001b[A\n",
            "Map:  88% 6181/6999 [00:09<00:01, 598.77 examples/s]\u001b[A\n",
            "Map:  89% 6253/6999 [00:09<00:01, 626.09 examples/s]\u001b[A\n",
            "Map:  91% 6355/6999 [00:09<00:01, 641.06 examples/s]\u001b[A\n",
            "Map:  92% 6424/6999 [00:09<00:00, 650.19 examples/s]\u001b[A\n",
            "Map:  93% 6509/6999 [00:09<00:00, 696.54 examples/s]\u001b[A\n",
            "Map:  94% 6587/6999 [00:09<00:00, 717.79 examples/s]\u001b[A\n",
            "Map:  95% 6669/6999 [00:10<00:00, 744.77 examples/s]\u001b[A\n",
            "Map:  96% 6750/6999 [00:10<00:00, 761.02 examples/s]\u001b[A\n",
            "Map:  98% 6836/6999 [00:10<00:00, 781.79 examples/s]\u001b[A\n",
            "Map: 100% 6999/6999 [00:10<00:00, 653.15 examples/s]\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "                         \n",
            "\u001b[A{'loss': 1.2414, 'grad_norm': 0.41749829053878784, 'learning_rate': 0.0003, 'epoch': 0.02}\n",
            "  0% 0/3 [11:32<?, ?it/s]\n",
            "  2% 1/55 [00:11<10:25, 11.58s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1882, 'grad_norm': 0.4115920662879944, 'learning_rate': 0.0002945454545454545, 'epoch': 0.04}\n",
            "  0% 0/3 [11:44<?, ?it/s]\n",
            "  4% 2/55 [00:23<10:13, 11.57s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1564, 'grad_norm': 0.42104023694992065, 'learning_rate': 0.00028909090909090904, 'epoch': 0.05}\n",
            "  0% 0/3 [11:55<?, ?it/s]\n",
            "  5% 3/55 [00:34<10:00, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0851, 'grad_norm': 0.34372952580451965, 'learning_rate': 0.0002836363636363636, 'epoch': 0.07}\n",
            "  0% 0/3 [12:07<?, ?it/s]\n",
            "  7% 4/55 [00:46<09:48, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1151, 'grad_norm': 0.32988440990448, 'learning_rate': 0.00027818181818181815, 'epoch': 0.09}\n",
            "  0% 0/3 [12:18<?, ?it/s]\n",
            "  9% 5/55 [00:57<09:37, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0744, 'grad_norm': 0.3359152376651764, 'learning_rate': 0.0002727272727272727, 'epoch': 0.11}\n",
            "  0% 0/3 [12:30<?, ?it/s]\n",
            " 11% 6/55 [01:09<09:25, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0514, 'grad_norm': 0.3720223307609558, 'learning_rate': 0.0002672727272727272, 'epoch': 0.13}\n",
            "  0% 0/3 [12:41<?, ?it/s]\n",
            " 13% 7/55 [01:20<09:14, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0711, 'grad_norm': 0.5238651633262634, 'learning_rate': 0.0002618181818181818, 'epoch': 0.15}\n",
            "  0% 0/3 [12:53<?, ?it/s]\n",
            " 15% 8/55 [01:32<09:02, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0346, 'grad_norm': 0.5255501866340637, 'learning_rate': 0.00025636363636363633, 'epoch': 0.16}\n",
            "  0% 0/3 [13:05<?, ?it/s]\n",
            " 16% 9/55 [01:43<08:51, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0139, 'grad_norm': 0.37484073638916016, 'learning_rate': 0.00025090909090909086, 'epoch': 0.18}\n",
            "  0% 0/3 [13:16<?, ?it/s]\n",
            " 18% 10/55 [01:55<08:39, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0432, 'grad_norm': 0.3944041430950165, 'learning_rate': 0.00024545454545454545, 'epoch': 0.2}\n",
            "  0% 0/3 [13:28<?, ?it/s]\n",
            " 20% 11/55 [02:07<08:28, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9549, 'grad_norm': 0.2952907681465149, 'learning_rate': 0.00023999999999999998, 'epoch': 0.22}\n",
            "  0% 0/3 [13:39<?, ?it/s]\n",
            " 22% 12/55 [02:18<08:16, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.956, 'grad_norm': 0.2671055197715759, 'learning_rate': 0.00023454545454545454, 'epoch': 0.24}\n",
            "  0% 0/3 [13:51<?, ?it/s]\n",
            " 24% 13/55 [02:30<08:04, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9682, 'grad_norm': 0.2698034644126892, 'learning_rate': 0.00022909090909090907, 'epoch': 0.26}\n",
            "  0% 0/3 [14:02<?, ?it/s]\n",
            " 25% 14/55 [02:41<07:53, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9643, 'grad_norm': 0.263522744178772, 'learning_rate': 0.00022363636363636363, 'epoch': 0.27}\n",
            "  0% 0/3 [14:14<?, ?it/s]\n",
            " 27% 15/55 [02:53<07:41, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9555, 'grad_norm': 0.24569721519947052, 'learning_rate': 0.00021818181818181816, 'epoch': 0.29}\n",
            "  0% 0/3 [14:25<?, ?it/s]\n",
            " 29% 16/55 [03:04<07:29, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9707, 'grad_norm': 0.25284507870674133, 'learning_rate': 0.00021272727272727272, 'epoch': 0.31}\n",
            "  0% 0/3 [14:37<?, ?it/s]\n",
            " 31% 17/55 [03:16<07:18, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9559, 'grad_norm': 0.2165517956018448, 'learning_rate': 0.00020727272727272725, 'epoch': 0.33}\n",
            "  0% 0/3 [14:48<?, ?it/s]\n",
            " 33% 18/55 [03:27<07:06, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9588, 'grad_norm': 0.1892988085746765, 'learning_rate': 0.0002018181818181818, 'epoch': 0.35}\n",
            "  0% 0/3 [15:00<?, ?it/s]\n",
            " 35% 19/55 [03:39<06:55, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9321, 'grad_norm': 0.17879019677639008, 'learning_rate': 0.00019636363636363634, 'epoch': 0.37}\n",
            "  0% 0/3 [15:11<?, ?it/s]\n",
            " 36% 20/55 [03:50<06:43, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.947, 'grad_norm': 0.16690683364868164, 'learning_rate': 0.0001909090909090909, 'epoch': 0.38}\n",
            "  0% 0/3 [15:23<?, ?it/s]\n",
            " 38% 21/55 [04:02<06:32, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9344, 'grad_norm': 0.15063482522964478, 'learning_rate': 0.00018545454545454543, 'epoch': 0.4}\n",
            "  0% 0/3 [15:35<?, ?it/s]\n",
            " 40% 22/55 [04:13<06:20, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9066, 'grad_norm': 0.14476096630096436, 'learning_rate': 0.00017999999999999998, 'epoch': 0.42}\n",
            "  0% 0/3 [15:46<?, ?it/s]\n",
            " 42% 23/55 [04:25<06:08, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9501, 'grad_norm': 0.1397256851196289, 'learning_rate': 0.00017454545454545452, 'epoch': 0.44}\n",
            "  0% 0/3 [15:58<?, ?it/s]\n",
            " 44% 24/55 [04:36<05:57, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9336, 'grad_norm': 0.1426502913236618, 'learning_rate': 0.00016909090909090907, 'epoch': 0.46}\n",
            "  0% 0/3 [16:09<?, ?it/s]\n",
            " 45% 25/55 [04:48<05:46, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9449, 'grad_norm': 0.12857657670974731, 'learning_rate': 0.0001636363636363636, 'epoch': 0.47}\n",
            "  0% 0/3 [16:21<?, ?it/s]\n",
            " 47% 26/55 [05:00<05:34, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9311, 'grad_norm': 0.13185063004493713, 'learning_rate': 0.00015818181818181816, 'epoch': 0.49}\n",
            "  0% 0/3 [16:32<?, ?it/s]\n",
            " 49% 27/55 [05:11<05:23, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.958, 'grad_norm': 0.1309920996427536, 'learning_rate': 0.0001527272727272727, 'epoch': 0.51}\n",
            "  0% 0/3 [16:44<?, ?it/s]\n",
            " 51% 28/55 [05:23<05:11, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9408, 'grad_norm': 0.13130569458007812, 'learning_rate': 0.00014727272727272725, 'epoch': 0.53}\n",
            "  0% 0/3 [16:55<?, ?it/s]\n",
            " 53% 29/55 [05:34<05:00, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9166, 'grad_norm': 0.12668414413928986, 'learning_rate': 0.0001418181818181818, 'epoch': 0.55}\n",
            "  0% 0/3 [17:07<?, ?it/s]\n",
            " 55% 30/55 [05:46<04:48, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9229, 'grad_norm': 0.1227787658572197, 'learning_rate': 0.00013636363636363634, 'epoch': 0.57}\n",
            "  0% 0/3 [17:18<?, ?it/s]\n",
            " 56% 31/55 [05:57<04:37, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9299, 'grad_norm': 0.1378077119588852, 'learning_rate': 0.0001309090909090909, 'epoch': 0.58}\n",
            "  0% 0/3 [17:30<?, ?it/s]\n",
            " 58% 32/55 [06:09<04:25, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9457, 'grad_norm': 0.12485279887914658, 'learning_rate': 0.00012545454545454543, 'epoch': 0.6}\n",
            "  0% 0/3 [17:42<?, ?it/s]\n",
            " 60% 33/55 [06:20<04:14, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9584, 'grad_norm': 0.12221486866474152, 'learning_rate': 0.00011999999999999999, 'epoch': 0.62}\n",
            "  0% 0/3 [17:53<?, ?it/s]\n",
            " 62% 34/55 [06:32<04:02, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9456, 'grad_norm': 0.12951181828975677, 'learning_rate': 0.00011454545454545453, 'epoch': 0.64}\n",
            "  0% 0/3 [18:05<?, ?it/s]\n",
            " 64% 35/55 [06:43<03:50, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9108, 'grad_norm': 0.12140251696109772, 'learning_rate': 0.00010909090909090908, 'epoch': 0.66}\n",
            "  0% 0/3 [18:16<?, ?it/s]\n",
            " 65% 36/55 [06:55<03:39, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9227, 'grad_norm': 0.11590489745140076, 'learning_rate': 0.00010363636363636362, 'epoch': 0.68}\n",
            "  0% 0/3 [18:28<?, ?it/s]\n",
            " 67% 37/55 [07:07<03:27, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9272, 'grad_norm': 0.12565946578979492, 'learning_rate': 9.818181818181817e-05, 'epoch': 0.69}\n",
            "  0% 0/3 [18:39<?, ?it/s]\n",
            " 69% 38/55 [07:18<03:16, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9046, 'grad_norm': 0.1150812953710556, 'learning_rate': 9.272727272727271e-05, 'epoch': 0.71}\n",
            "  0% 0/3 [18:51<?, ?it/s]\n",
            " 71% 39/55 [07:30<03:04, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9094, 'grad_norm': 0.12880975008010864, 'learning_rate': 8.727272727272726e-05, 'epoch': 0.73}\n",
            "  0% 0/3 [19:02<?, ?it/s]\n",
            " 73% 40/55 [07:41<02:53, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9522, 'grad_norm': 0.11786016076803207, 'learning_rate': 8.18181818181818e-05, 'epoch': 0.75}\n",
            "  0% 0/3 [19:14<?, ?it/s]\n",
            " 75% 41/55 [07:53<02:41, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9109, 'grad_norm': 0.11931852996349335, 'learning_rate': 7.636363636363635e-05, 'epoch': 0.77}\n",
            "  0% 0/3 [19:25<?, ?it/s]\n",
            " 76% 42/55 [08:04<02:30, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9159, 'grad_norm': 0.1186150386929512, 'learning_rate': 7.09090909090909e-05, 'epoch': 0.79}\n",
            "  0% 0/3 [19:37<?, ?it/s]\n",
            " 78% 43/55 [08:16<02:18, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9108, 'grad_norm': 0.12399463355541229, 'learning_rate': 6.545454545454545e-05, 'epoch': 0.8}\n",
            "  0% 0/3 [19:48<?, ?it/s]\n",
            " 80% 44/55 [08:27<02:06, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9369, 'grad_norm': 0.11470416188240051, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.82}\n",
            "  0% 0/3 [20:00<?, ?it/s]\n",
            " 82% 45/55 [08:39<01:55, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9482, 'grad_norm': 0.11447172611951828, 'learning_rate': 5.454545454545454e-05, 'epoch': 0.84}\n",
            "  0% 0/3 [20:11<?, ?it/s]\n",
            " 84% 46/55 [08:50<01:43, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9075, 'grad_norm': 0.12030235677957535, 'learning_rate': 4.9090909090909084e-05, 'epoch': 0.86}\n",
            "  0% 0/3 [20:23<?, ?it/s]\n",
            " 85% 47/55 [09:02<01:32, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9313, 'grad_norm': 0.1216338500380516, 'learning_rate': 4.363636363636363e-05, 'epoch': 0.88}\n",
            "  0% 0/3 [20:35<?, ?it/s]\n",
            " 87% 48/55 [09:13<01:20, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9194, 'grad_norm': 0.11182045191526413, 'learning_rate': 3.8181818181818174e-05, 'epoch': 0.89}\n",
            "  0% 0/3 [20:46<?, ?it/s]\n",
            " 89% 49/55 [09:25<01:09, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9073, 'grad_norm': 0.11656992882490158, 'learning_rate': 3.2727272727272725e-05, 'epoch': 0.91}\n",
            "  0% 0/3 [20:58<?, ?it/s]\n",
            " 91% 50/55 [09:37<00:57, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9368, 'grad_norm': 0.11862361431121826, 'learning_rate': 2.727272727272727e-05, 'epoch': 0.93}\n",
            "  0% 0/3 [21:09<?, ?it/s]\n",
            " 93% 51/55 [09:48<00:46, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8752, 'grad_norm': 0.1168942004442215, 'learning_rate': 2.1818181818181814e-05, 'epoch': 0.95}\n",
            "  0% 0/3 [21:21<?, ?it/s]\n",
            " 95% 52/55 [10:00<00:34, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9316, 'grad_norm': 0.12289497256278992, 'learning_rate': 1.6363636363636363e-05, 'epoch': 0.97}\n",
            "  0% 0/3 [21:32<?, ?it/s]\n",
            " 96% 53/55 [10:11<00:23, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.929, 'grad_norm': 0.1206563264131546, 'learning_rate': 1.0909090909090907e-05, 'epoch': 0.99}\n",
            "  0% 0/3 [21:44<?, ?it/s]\n",
            " 98% 54/55 [10:23<00:11, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9144, 'grad_norm': 0.13500405848026276, 'learning_rate': 5.454545454545454e-06, 'epoch': 1.0}\n",
            "  0% 0/3 [21:52<?, ?it/s]\n",
            "                         \n",
            "\u001b[A{'train_runtime': 631.7562, 'train_samples_per_second': 11.079, 'train_steps_per_second': 0.087, 'train_loss': 0.9665211027318781, 'epoch': 1.0}\n",
            "  0% 0/3 [21:52<?, ?it/s]\n",
            "100% 55/55 [10:31<00:00, 11.49s/it]\n",
            "\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train split: 6999 examples [00:00, 31293.47 examples/s]\n",
            "\n",
            "Map:   0% 0/6999 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:   1% 77/6999 [00:00<00:09, 762.37 examples/s]\u001b[A\n",
            "Map:   3% 189/6999 [00:00<00:09, 740.38 examples/s]\u001b[A\n",
            "Map:   4% 264/6999 [00:00<00:09, 740.81 examples/s]\u001b[A\n",
            "Map:   5% 341/6999 [00:00<00:08, 747.82 examples/s]\u001b[A\n",
            "Map:   6% 419/6999 [00:00<00:08, 754.73 examples/s]\u001b[A\n",
            "Map:   7% 502/6999 [00:00<00:08, 775.75 examples/s]\u001b[A\n",
            "Map:   9% 611/6999 [00:00<00:08, 746.45 examples/s]\u001b[A\n",
            "Map:  10% 689/6999 [00:00<00:08, 754.09 examples/s]\u001b[A\n",
            "Map:  11% 793/6999 [00:01<00:08, 726.54 examples/s]\u001b[A\n",
            "Map:  12% 867/6999 [00:01<00:08, 724.10 examples/s]\u001b[A\n",
            "Map:  14% 976/6999 [00:01<00:08, 700.79 examples/s]\u001b[A\n",
            "Map:  15% 1078/6999 [00:01<00:11, 526.07 examples/s]\u001b[A\n",
            "Map:  16% 1152/6999 [00:01<00:10, 565.35 examples/s]\u001b[A\n",
            "Map:  17% 1223/6999 [00:01<00:09, 596.37 examples/s]\u001b[A\n",
            "Map:  19% 1299/6999 [00:01<00:08, 633.37 examples/s]\u001b[A\n",
            "Map:  20% 1377/6999 [00:02<00:08, 666.23 examples/s]\u001b[A\n",
            "Map:  21% 1462/6999 [00:02<00:07, 713.79 examples/s]\u001b[A\n",
            "Map:  22% 1544/6999 [00:02<00:07, 741.39 examples/s]\u001b[A\n",
            "Map:  24% 1659/6999 [00:02<00:07, 745.46 examples/s]\u001b[A\n",
            "Map:  25% 1770/6999 [00:02<00:07, 736.47 examples/s]\u001b[A\n",
            "Map:  26% 1852/6999 [00:02<00:06, 752.50 examples/s]\u001b[A\n",
            "Map:  28% 1963/6999 [00:02<00:06, 742.27 examples/s]\u001b[A\n",
            "Map:  30% 2069/6999 [00:03<00:08, 547.78 examples/s]\u001b[A\n",
            "Map:  31% 2142/6999 [00:03<00:08, 581.07 examples/s]\u001b[A\n",
            "Map:  32% 2246/6999 [00:03<00:07, 610.49 examples/s]\u001b[A\n",
            "Map:  33% 2320/6999 [00:03<00:07, 637.62 examples/s]\u001b[A\n",
            "Map:  34% 2396/6999 [00:03<00:06, 662.92 examples/s]\u001b[A\n",
            "Map:  35% 2478/6999 [00:03<00:06, 699.45 examples/s]\u001b[A\n",
            "Map:  36% 2554/6999 [00:03<00:06, 711.39 examples/s]\u001b[A\n",
            "Map:  38% 2667/6999 [00:03<00:05, 722.78 examples/s]\u001b[A\n",
            "Map:  39% 2750/6999 [00:04<00:05, 748.35 examples/s]\u001b[A\n",
            "Map:  40% 2830/6999 [00:04<00:05, 759.48 examples/s]\u001b[A\n",
            "Map:  42% 2910/6999 [00:04<00:05, 768.78 examples/s]\u001b[A\n",
            "Map:  43% 3000/6999 [00:04<00:07, 533.14 examples/s]\u001b[A\n",
            "Map:  44% 3070/6999 [00:04<00:06, 567.73 examples/s]\u001b[A\n",
            "Map:  45% 3151/6999 [00:04<00:06, 622.31 examples/s]\u001b[A\n",
            "Map:  47% 3265/6999 [00:04<00:05, 664.87 examples/s]\u001b[A\n",
            "Map:  48% 3346/6999 [00:04<00:05, 699.13 examples/s]\u001b[A\n",
            "Map:  49% 3449/6999 [00:05<00:05, 690.93 examples/s]\u001b[A\n",
            "Map:  50% 3525/6999 [00:05<00:04, 706.23 examples/s]\u001b[A\n",
            "Map:  52% 3605/6999 [00:05<00:04, 725.91 examples/s]\u001b[A\n",
            "Map:  53% 3713/6999 [00:05<00:04, 718.27 examples/s]\u001b[A\n",
            "Map:  54% 3795/6999 [00:05<00:04, 739.11 examples/s]\u001b[A\n",
            "Map:  55% 3871/6999 [00:05<00:04, 742.45 examples/s]\u001b[A\n",
            "Map:  56% 3950/6999 [00:05<00:04, 754.67 examples/s]\u001b[A\n",
            "Map:  58% 4036/6999 [00:06<00:05, 523.41 examples/s]\u001b[A\n",
            "Map:  59% 4104/6999 [00:06<00:05, 555.96 examples/s]\u001b[A\n",
            "Map:  60% 4173/6999 [00:06<00:04, 584.52 examples/s]\u001b[A\n",
            "Map:  61% 4278/6999 [00:06<00:04, 619.95 examples/s]\u001b[A\n",
            "Map:  62% 4351/6999 [00:06<00:04, 644.47 examples/s]\u001b[A\n",
            "Map:  63% 4424/6999 [00:06<00:03, 664.74 examples/s]\u001b[A\n",
            "Map:  65% 4528/6999 [00:06<00:03, 671.16 examples/s]\u001b[A\n",
            "Map:  66% 4605/6999 [00:06<00:03, 691.36 examples/s]\u001b[A\n",
            "Map:  67% 4690/6999 [00:06<00:03, 725.94 examples/s]\u001b[A\n",
            "Map:  69% 4800/6999 [00:07<00:03, 725.82 examples/s]\u001b[A\n",
            "Map:  70% 4907/6999 [00:07<00:02, 715.32 examples/s]\u001b[A\n",
            "Map:  71% 4995/6999 [00:07<00:02, 751.45 examples/s]\u001b[A\n",
            "Map:  73% 5076/6999 [00:07<00:03, 531.12 examples/s]\u001b[A\n",
            "Map:  74% 5157/6999 [00:07<00:03, 585.65 examples/s]\u001b[A\n",
            "Map:  75% 5233/6999 [00:07<00:02, 619.71 examples/s]\u001b[A\n",
            "Map:  76% 5310/6999 [00:07<00:02, 653.73 examples/s]\u001b[A\n",
            "Map:  77% 5387/6999 [00:08<00:02, 679.80 examples/s]\u001b[A\n",
            "Map:  78% 5464/6999 [00:08<00:02, 702.74 examples/s]\u001b[A\n",
            "Map:  80% 5571/6999 [00:08<00:02, 702.81 examples/s]\u001b[A\n",
            "Map:  81% 5670/6999 [00:08<00:01, 682.12 examples/s]\u001b[A\n",
            "Map:  82% 5769/6999 [00:08<00:01, 668.70 examples/s]\u001b[A\n",
            "Map:  84% 5848/6999 [00:08<00:01, 695.56 examples/s]\u001b[A\n",
            "Map:  85% 5923/6999 [00:08<00:01, 707.92 examples/s]\u001b[A\n",
            "Map:  86% 6000/6999 [00:09<00:01, 505.13 examples/s]\u001b[A\n",
            "Map:  87% 6071/6999 [00:09<00:01, 546.55 examples/s]\u001b[A\n",
            "Map:  88% 6151/6999 [00:09<00:01, 602.01 examples/s]\u001b[A\n",
            "Map:  89% 6221/6999 [00:09<00:01, 616.66 examples/s]\u001b[A\n",
            "Map:  90% 6289/6999 [00:09<00:01, 631.17 examples/s]\u001b[A\n",
            "Map:  91% 6358/6999 [00:09<00:01, 638.12 examples/s]\u001b[A\n",
            "Map:  92% 6441/6999 [00:09<00:00, 687.04 examples/s]\u001b[A\n",
            "Map:  93% 6519/6999 [00:09<00:00, 709.82 examples/s]\u001b[A\n",
            "Map:  94% 6596/6999 [00:09<00:00, 725.10 examples/s]\u001b[A\n",
            "Map:  96% 6704/6999 [00:10<00:00, 721.37 examples/s]\u001b[A\n",
            "Map:  97% 6781/6999 [00:10<00:00, 732.04 examples/s]\u001b[A\n",
            "Map:  98% 6886/6999 [00:10<00:00, 715.00 examples/s]\u001b[A\n",
            "Map: 100% 6999/6999 [00:10<00:00, 657.24 examples/s]\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "                         \n",
            "\u001b[A{'loss': 1.2266, 'grad_norm': 0.4113815426826477, 'learning_rate': 0.0003, 'epoch': 0.02}\n",
            "  0% 0/3 [22:16<?, ?it/s]\n",
            "  2% 1/55 [00:11<10:25, 11.58s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1711, 'grad_norm': 0.4121643602848053, 'learning_rate': 0.0002945454545454545, 'epoch': 0.04}\n",
            "  0% 0/3 [22:28<?, ?it/s]\n",
            "  4% 2/55 [00:23<10:12, 11.56s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1869, 'grad_norm': 0.4666295349597931, 'learning_rate': 0.00028909090909090904, 'epoch': 0.05}\n",
            "  0% 0/3 [22:39<?, ?it/s]\n",
            "  5% 3/55 [00:34<10:00, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0984, 'grad_norm': 0.3762085437774658, 'learning_rate': 0.0002836363636363636, 'epoch': 0.07}\n",
            "  0% 0/3 [22:51<?, ?it/s]\n",
            "  7% 4/55 [00:46<09:49, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.104, 'grad_norm': 0.3423580229282379, 'learning_rate': 0.00027818181818181815, 'epoch': 0.09}\n",
            "  0% 0/3 [23:03<?, ?it/s]\n",
            "  9% 5/55 [00:57<09:37, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0885, 'grad_norm': 0.35469263792037964, 'learning_rate': 0.0002727272727272727, 'epoch': 0.11}\n",
            "  0% 0/3 [23:14<?, ?it/s]\n",
            " 11% 6/55 [01:09<09:25, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0797, 'grad_norm': 0.3864395320415497, 'learning_rate': 0.0002672727272727272, 'epoch': 0.13}\n",
            "  0% 0/3 [23:26<?, ?it/s]\n",
            " 13% 7/55 [01:20<09:13, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0467, 'grad_norm': 0.5712045431137085, 'learning_rate': 0.0002618181818181818, 'epoch': 0.15}\n",
            "  0% 0/3 [23:37<?, ?it/s]\n",
            " 15% 8/55 [01:32<09:02, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0095, 'grad_norm': 0.4237229526042938, 'learning_rate': 0.00025636363636363633, 'epoch': 0.16}\n",
            "  0% 0/3 [23:49<?, ?it/s]\n",
            " 16% 9/55 [01:43<08:50, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.005, 'grad_norm': 0.3631630539894104, 'learning_rate': 0.00025090909090909086, 'epoch': 0.18}\n",
            "  0% 0/3 [24:00<?, ?it/s]\n",
            " 18% 10/55 [01:55<08:39, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9878, 'grad_norm': 0.34109658002853394, 'learning_rate': 0.00024545454545454545, 'epoch': 0.2}\n",
            "  0% 0/3 [24:12<?, ?it/s]\n",
            " 20% 11/55 [02:06<08:27, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0027, 'grad_norm': 0.3188251256942749, 'learning_rate': 0.00023999999999999998, 'epoch': 0.22}\n",
            "  0% 0/3 [24:23<?, ?it/s]\n",
            " 22% 12/55 [02:18<08:15, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9575, 'grad_norm': 0.27197226881980896, 'learning_rate': 0.00023454545454545454, 'epoch': 0.24}\n",
            "  0% 0/3 [24:35<?, ?it/s]\n",
            " 24% 13/55 [02:30<08:04, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9618, 'grad_norm': 0.26054394245147705, 'learning_rate': 0.00022909090909090907, 'epoch': 0.26}\n",
            "  0% 0/3 [24:46<?, ?it/s]\n",
            " 25% 14/55 [02:41<07:52, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.987, 'grad_norm': 0.25244030356407166, 'learning_rate': 0.00022363636363636363, 'epoch': 0.27}\n",
            "  0% 0/3 [24:58<?, ?it/s]\n",
            " 27% 15/55 [02:53<07:41, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9535, 'grad_norm': 0.2392807900905609, 'learning_rate': 0.00021818181818181816, 'epoch': 0.29}\n",
            "  0% 0/3 [25:09<?, ?it/s]\n",
            " 29% 16/55 [03:04<07:30, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9673, 'grad_norm': 0.2322617620229721, 'learning_rate': 0.00021272727272727272, 'epoch': 0.31}\n",
            "  0% 0/3 [25:21<?, ?it/s]\n",
            " 31% 17/55 [03:16<07:18, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9172, 'grad_norm': 0.22377333045005798, 'learning_rate': 0.00020727272727272725, 'epoch': 0.33}\n",
            "  0% 0/3 [25:32<?, ?it/s]\n",
            " 33% 18/55 [03:27<07:06, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9408, 'grad_norm': 0.19948740303516388, 'learning_rate': 0.0002018181818181818, 'epoch': 0.35}\n",
            "  0% 0/3 [25:44<?, ?it/s]\n",
            " 35% 19/55 [03:39<06:55, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9223, 'grad_norm': 0.17065945267677307, 'learning_rate': 0.00019636363636363634, 'epoch': 0.37}\n",
            "  0% 0/3 [25:56<?, ?it/s]\n",
            " 36% 20/55 [03:50<06:43, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9607, 'grad_norm': 0.16264094412326813, 'learning_rate': 0.0001909090909090909, 'epoch': 0.38}\n",
            "  0% 0/3 [26:07<?, ?it/s]\n",
            " 38% 21/55 [04:02<06:32, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.947, 'grad_norm': 0.15852653980255127, 'learning_rate': 0.00018545454545454543, 'epoch': 0.4}\n",
            "  0% 0/3 [26:19<?, ?it/s]\n",
            " 40% 22/55 [04:13<06:20, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9276, 'grad_norm': 0.1440127193927765, 'learning_rate': 0.00017999999999999998, 'epoch': 0.42}\n",
            "  0% 0/3 [26:30<?, ?it/s]\n",
            " 42% 23/55 [04:25<06:09, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9506, 'grad_norm': 0.1556384265422821, 'learning_rate': 0.00017454545454545452, 'epoch': 0.44}\n",
            "  0% 0/3 [26:42<?, ?it/s]\n",
            " 44% 24/55 [04:36<05:57, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8943, 'grad_norm': 0.13595853745937347, 'learning_rate': 0.00016909090909090907, 'epoch': 0.46}\n",
            "  0% 0/3 [26:53<?, ?it/s]\n",
            " 45% 25/55 [04:48<05:46, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9223, 'grad_norm': 0.14654433727264404, 'learning_rate': 0.0001636363636363636, 'epoch': 0.47}\n",
            "  0% 0/3 [27:05<?, ?it/s]\n",
            " 47% 26/55 [05:00<05:34, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9717, 'grad_norm': 0.14476913213729858, 'learning_rate': 0.00015818181818181816, 'epoch': 0.49}\n",
            "  0% 0/3 [27:16<?, ?it/s]\n",
            " 49% 27/55 [05:11<05:23, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9099, 'grad_norm': 0.13089674711227417, 'learning_rate': 0.0001527272727272727, 'epoch': 0.51}\n",
            "  0% 0/3 [27:28<?, ?it/s]\n",
            " 51% 28/55 [05:23<05:11, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8775, 'grad_norm': 0.13805030286312103, 'learning_rate': 0.00014727272727272725, 'epoch': 0.53}\n",
            "  0% 0/3 [27:39<?, ?it/s]\n",
            " 53% 29/55 [05:34<05:00, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.947, 'grad_norm': 0.13679270446300507, 'learning_rate': 0.0001418181818181818, 'epoch': 0.55}\n",
            "  0% 0/3 [27:51<?, ?it/s]\n",
            " 55% 30/55 [05:46<04:48, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9108, 'grad_norm': 0.1240847259759903, 'learning_rate': 0.00013636363636363634, 'epoch': 0.57}\n",
            "  0% 0/3 [28:03<?, ?it/s]\n",
            " 56% 31/55 [05:57<04:37, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9172, 'grad_norm': 0.12739406526088715, 'learning_rate': 0.0001309090909090909, 'epoch': 0.58}\n",
            "  0% 0/3 [28:14<?, ?it/s]\n",
            " 58% 32/55 [06:09<04:25, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9035, 'grad_norm': 0.12540365755558014, 'learning_rate': 0.00012545454545454543, 'epoch': 0.6}\n",
            "  0% 0/3 [28:26<?, ?it/s]\n",
            " 60% 33/55 [06:20<04:14, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9353, 'grad_norm': 0.12003019452095032, 'learning_rate': 0.00011999999999999999, 'epoch': 0.62}\n",
            "  0% 0/3 [28:37<?, ?it/s]\n",
            " 62% 34/55 [06:32<04:02, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9053, 'grad_norm': 0.12813709676265717, 'learning_rate': 0.00011454545454545453, 'epoch': 0.64}\n",
            "  0% 0/3 [28:49<?, ?it/s]\n",
            " 64% 35/55 [06:43<03:50, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9361, 'grad_norm': 0.11879044026136398, 'learning_rate': 0.00010909090909090908, 'epoch': 0.66}\n",
            "  0% 0/3 [29:00<?, ?it/s]\n",
            " 65% 36/55 [06:55<03:39, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9057, 'grad_norm': 0.12069723755121231, 'learning_rate': 0.00010363636363636362, 'epoch': 0.68}\n",
            "  0% 0/3 [29:12<?, ?it/s]\n",
            " 67% 37/55 [07:07<03:27, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9491, 'grad_norm': 0.13580816984176636, 'learning_rate': 9.818181818181817e-05, 'epoch': 0.69}\n",
            "  0% 0/3 [29:23<?, ?it/s]\n",
            " 69% 38/55 [07:18<03:16, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9122, 'grad_norm': 0.11324837803840637, 'learning_rate': 9.272727272727271e-05, 'epoch': 0.71}\n",
            "  0% 0/3 [29:35<?, ?it/s]\n",
            " 71% 39/55 [07:30<03:04, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9128, 'grad_norm': 0.11524461209774017, 'learning_rate': 8.727272727272726e-05, 'epoch': 0.73}\n",
            "  0% 0/3 [29:46<?, ?it/s]\n",
            " 73% 40/55 [07:41<02:53, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8889, 'grad_norm': 0.12809878587722778, 'learning_rate': 8.18181818181818e-05, 'epoch': 0.75}\n",
            "  0% 0/3 [29:58<?, ?it/s]\n",
            " 75% 41/55 [07:53<02:41, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9787, 'grad_norm': 0.12390189617872238, 'learning_rate': 7.636363636363635e-05, 'epoch': 0.77}\n",
            "  0% 0/3 [30:09<?, ?it/s]\n",
            " 76% 42/55 [08:04<02:30, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9233, 'grad_norm': 0.1194683313369751, 'learning_rate': 7.09090909090909e-05, 'epoch': 0.79}\n",
            "  0% 0/3 [30:21<?, ?it/s]\n",
            " 78% 43/55 [08:16<02:18, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9358, 'grad_norm': 0.12528003752231598, 'learning_rate': 6.545454545454545e-05, 'epoch': 0.8}\n",
            "  0% 0/3 [30:33<?, ?it/s]\n",
            " 80% 44/55 [08:27<02:07, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9034, 'grad_norm': 0.11046498268842697, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.82}\n",
            "  0% 0/3 [30:44<?, ?it/s]\n",
            " 82% 45/55 [08:39<01:55, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9091, 'grad_norm': 0.11626376211643219, 'learning_rate': 5.454545454545454e-05, 'epoch': 0.84}\n",
            "  0% 0/3 [30:56<?, ?it/s]\n",
            " 84% 46/55 [08:50<01:43, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8964, 'grad_norm': 0.11818104982376099, 'learning_rate': 4.9090909090909084e-05, 'epoch': 0.86}\n",
            "  0% 0/3 [31:07<?, ?it/s]\n",
            " 85% 47/55 [09:02<01:32, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9138, 'grad_norm': 0.11771462112665176, 'learning_rate': 4.363636363636363e-05, 'epoch': 0.88}\n",
            "  0% 0/3 [31:19<?, ?it/s]\n",
            " 87% 48/55 [09:14<01:20, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.943, 'grad_norm': 0.1211119294166565, 'learning_rate': 3.8181818181818174e-05, 'epoch': 0.89}\n",
            "  0% 0/3 [31:30<?, ?it/s]\n",
            " 89% 49/55 [09:25<01:09, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.888, 'grad_norm': 0.12119735777378082, 'learning_rate': 3.2727272727272725e-05, 'epoch': 0.91}\n",
            "  0% 0/3 [31:42<?, ?it/s]\n",
            " 91% 50/55 [09:37<00:57, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9151, 'grad_norm': 0.11912994086742401, 'learning_rate': 2.727272727272727e-05, 'epoch': 0.93}\n",
            "  0% 0/3 [31:53<?, ?it/s]\n",
            " 93% 51/55 [09:48<00:46, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9384, 'grad_norm': 0.1168317198753357, 'learning_rate': 2.1818181818181814e-05, 'epoch': 0.95}\n",
            "  0% 0/3 [32:05<?, ?it/s]\n",
            " 95% 52/55 [10:00<00:34, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9566, 'grad_norm': 0.12548549473285675, 'learning_rate': 1.6363636363636363e-05, 'epoch': 0.97}\n",
            "  0% 0/3 [32:16<?, ?it/s]\n",
            " 96% 53/55 [10:11<00:23, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9201, 'grad_norm': 0.12412265688180923, 'learning_rate': 1.0909090909090907e-05, 'epoch': 0.99}\n",
            "  0% 0/3 [32:28<?, ?it/s]\n",
            " 98% 54/55 [10:23<00:11, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9166, 'grad_norm': 0.1371174305677414, 'learning_rate': 5.454545454545454e-06, 'epoch': 1.0}\n",
            "  0% 0/3 [32:36<?, ?it/s]\n",
            "                         \n",
            "\u001b[A{'train_runtime': 631.7937, 'train_samples_per_second': 11.078, 'train_steps_per_second': 0.087, 'train_loss': 0.9625095410780473, 'epoch': 1.0}\n",
            "  0% 0/3 [32:37<?, ?it/s]\n",
            "100% 55/55 [10:31<00:00, 11.49s/it]\n",
            "\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train split: 6999 examples [00:00, 30449.84 examples/s]\n",
            "\n",
            "Map:   0% 0/6999 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:   1% 70/6999 [00:00<00:10, 678.59 examples/s]\u001b[A\n",
            "Map:   2% 139/6999 [00:00<00:10, 681.11 examples/s]\u001b[A\n",
            "Map:   3% 208/6999 [00:00<00:09, 683.06 examples/s]\u001b[A\n",
            "Map:   4% 286/6999 [00:00<00:09, 719.21 examples/s]\u001b[A\n",
            "Map:   5% 363/6999 [00:00<00:09, 732.90 examples/s]\u001b[A\n",
            "Map:   7% 464/6999 [00:00<00:09, 691.90 examples/s]\u001b[A\n",
            "Map:   8% 537/6999 [00:00<00:09, 700.93 examples/s]\u001b[A\n",
            "Map:   9% 616/6999 [00:00<00:08, 719.88 examples/s]\u001b[A\n",
            "Map:  10% 695/6999 [00:00<00:08, 737.23 examples/s]\u001b[A\n",
            "Map:  11% 771/6999 [00:01<00:08, 739.82 examples/s]\u001b[A\n",
            "Map:  12% 855/6999 [00:01<00:08, 767.42 examples/s]\u001b[A\n",
            "Map:  14% 962/6999 [00:01<00:08, 743.34 examples/s]\u001b[A\n",
            "Map:  15% 1039/6999 [00:01<00:11, 520.08 examples/s]\u001b[A\n",
            "Map:  16% 1103/6999 [00:01<00:10, 544.20 examples/s]\u001b[A\n",
            "Map:  17% 1182/6999 [00:01<00:09, 599.74 examples/s]\u001b[A\n",
            "Map:  18% 1258/6999 [00:01<00:09, 637.05 examples/s]\u001b[A\n",
            "Map:  19% 1332/6999 [00:01<00:08, 661.09 examples/s]\u001b[A\n",
            "Map:  20% 1408/6999 [00:02<00:08, 683.73 examples/s]\u001b[A\n",
            "Map:  21% 1491/6999 [00:02<00:07, 721.10 examples/s]\u001b[A\n",
            "Map:  23% 1609/6999 [00:02<00:07, 742.17 examples/s]\u001b[A\n",
            "Map:  25% 1722/6999 [00:02<00:07, 740.93 examples/s]\u001b[A\n",
            "Map:  26% 1798/6999 [00:02<00:07, 740.91 examples/s]\u001b[A\n",
            "Map:  27% 1873/6999 [00:02<00:06, 734.17 examples/s]\u001b[A\n",
            "Map:  28% 1948/6999 [00:02<00:06, 732.92 examples/s]\u001b[A\n",
            "Map:  29% 2037/6999 [00:03<00:09, 517.00 examples/s]\u001b[A\n",
            "Map:  30% 2113/6999 [00:03<00:10, 448.42 examples/s]\u001b[A\n",
            "Map:  31% 2187/6999 [00:03<00:09, 497.92 examples/s]\u001b[A\n",
            "Map:  32% 2260/6999 [00:03<00:08, 545.23 examples/s]\u001b[A\n",
            "Map:  33% 2332/6999 [00:03<00:07, 584.85 examples/s]\u001b[A\n",
            "Map:  34% 2402/6999 [00:03<00:07, 610.25 examples/s]\u001b[A\n",
            "Map:  35% 2475/6999 [00:03<00:07, 636.24 examples/s]\u001b[A\n",
            "Map:  37% 2583/6999 [00:03<00:06, 661.48 examples/s]\u001b[A\n",
            "Map:  38% 2656/6999 [00:04<00:06, 674.48 examples/s]\u001b[A\n",
            "Map:  39% 2740/6999 [00:04<00:05, 715.28 examples/s]\u001b[A\n",
            "Map:  40% 2815/6999 [00:04<00:05, 722.78 examples/s]\u001b[A\n",
            "Map:  42% 2914/6999 [00:04<00:05, 697.90 examples/s]\u001b[A\n",
            "Map:  43% 2991/6999 [00:04<00:05, 714.18 examples/s]\u001b[A\n",
            "Map:  44% 3075/6999 [00:04<00:07, 506.88 examples/s]\u001b[A\n",
            "Map:  45% 3146/6999 [00:04<00:07, 545.44 examples/s]\u001b[A\n",
            "Map:  46% 3222/6999 [00:05<00:06, 592.37 examples/s]\u001b[A\n",
            "Map:  47% 3303/6999 [00:05<00:05, 644.12 examples/s]\u001b[A\n",
            "Map:  48% 3378/6999 [00:05<00:05, 668.90 examples/s]\u001b[A\n",
            "Map:  49% 3453/6999 [00:05<00:05, 684.38 examples/s]\u001b[A\n",
            "Map:  51% 3560/6999 [00:05<00:04, 689.96 examples/s]\u001b[A\n",
            "Map:  52% 3632/6999 [00:05<00:04, 695.50 examples/s]\u001b[A\n",
            "Map:  53% 3719/6999 [00:05<00:04, 739.82 examples/s]\u001b[A\n",
            "Map:  55% 3818/6999 [00:05<00:04, 703.49 examples/s]\u001b[A\n",
            "Map:  56% 3891/6999 [00:05<00:04, 708.85 examples/s]\u001b[A\n",
            "Map:  57% 3999/6999 [00:06<00:04, 705.88 examples/s]\u001b[A\n",
            "Map:  58% 4077/6999 [00:06<00:05, 509.31 examples/s]\u001b[A\n",
            "Map:  59% 4145/6999 [00:06<00:05, 541.06 examples/s]\u001b[A\n",
            "Map:  60% 4223/6999 [00:06<00:04, 592.93 examples/s]\u001b[A\n",
            "Map:  61% 4294/6999 [00:06<00:04, 616.78 examples/s]\u001b[A\n",
            "Map:  62% 4371/6999 [00:06<00:04, 654.86 examples/s]\u001b[A\n",
            "Map:  63% 4442/6999 [00:06<00:03, 665.20 examples/s]\u001b[A\n",
            "Map:  65% 4521/6999 [00:06<00:03, 698.21 examples/s]\u001b[A\n",
            "Map:  66% 4596/6999 [00:07<00:03, 708.58 examples/s]\u001b[A\n",
            "Map:  67% 4675/6999 [00:07<00:03, 728.08 examples/s]\u001b[A\n",
            "Map:  68% 4779/6999 [00:07<00:03, 704.83 examples/s]\u001b[A\n",
            "Map:  70% 4894/6999 [00:07<00:02, 724.24 examples/s]\u001b[A\n",
            "Map:  71% 4980/6999 [00:07<00:02, 752.09 examples/s]\u001b[A\n",
            "Map:  72% 5073/6999 [00:07<00:03, 540.35 examples/s]\u001b[A\n",
            "Map:  74% 5146/6999 [00:07<00:03, 573.20 examples/s]\u001b[A\n",
            "Map:  75% 5222/6999 [00:08<00:02, 613.88 examples/s]\u001b[A\n",
            "Map:  76% 5299/6999 [00:08<00:02, 649.31 examples/s]\u001b[A\n",
            "Map:  77% 5377/6999 [00:08<00:02, 680.26 examples/s]\u001b[A\n",
            "Map:  78% 5461/6999 [00:08<00:02, 720.08 examples/s]\u001b[A\n",
            "Map:  79% 5537/6999 [00:08<00:02, 730.02 examples/s]\u001b[A\n",
            "Map:  81% 5641/6999 [00:08<00:01, 709.30 examples/s]\u001b[A\n",
            "Map:  82% 5753/6999 [00:08<00:01, 716.19 examples/s]\u001b[A\n",
            "Map:  83% 5837/6999 [00:08<00:01, 736.90 examples/s]\u001b[A\n",
            "Map:  85% 5951/6999 [00:09<00:01, 740.57 examples/s]\u001b[A\n",
            "Map:  86% 6037/6999 [00:09<00:01, 537.16 examples/s]\u001b[A\n",
            "Map:  87% 6112/6999 [00:09<00:01, 576.82 examples/s]\u001b[A\n",
            "Map:  88% 6183/6999 [00:09<00:01, 603.34 examples/s]\u001b[A\n",
            "Map:  89% 6252/6999 [00:09<00:01, 623.23 examples/s]\u001b[A\n",
            "Map:  91% 6338/6999 [00:09<00:00, 676.83 examples/s]\u001b[A\n",
            "Map:  92% 6416/6999 [00:09<00:00, 700.31 examples/s]\u001b[A\n",
            "Map:  93% 6491/6999 [00:09<00:00, 712.05 examples/s]\u001b[A\n",
            "Map:  94% 6605/6999 [00:10<00:00, 727.39 examples/s]\u001b[A\n",
            "Map:  96% 6714/6999 [00:10<00:00, 722.75 examples/s]\u001b[A\n",
            "Map:  97% 6799/6999 [00:10<00:00, 750.00 examples/s]\u001b[A\n",
            "Map:  99% 6913/6999 [00:10<00:00, 752.35 examples/s]\u001b[A\n",
            "Map: 100% 6999/6999 [00:10<00:00, 648.08 examples/s]\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "                         \n",
            "\u001b[A{'loss': 1.1834, 'grad_norm': 0.4096372723579407, 'learning_rate': 0.0003, 'epoch': 0.02}\n",
            "  0% 0/3 [33:01<?, ?it/s]\n",
            "  2% 1/55 [00:11<10:25, 11.58s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1891, 'grad_norm': 0.40965425968170166, 'learning_rate': 0.0002945454545454545, 'epoch': 0.04}\n",
            "  0% 0/3 [33:12<?, ?it/s]\n",
            "  4% 2/55 [00:23<10:13, 11.57s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1717, 'grad_norm': 0.455639511346817, 'learning_rate': 0.00028909090909090904, 'epoch': 0.05}\n",
            "  0% 0/3 [33:24<?, ?it/s]\n",
            "  5% 3/55 [00:34<10:01, 11.56s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0996, 'grad_norm': 0.34688201546669006, 'learning_rate': 0.0002836363636363636, 'epoch': 0.07}\n",
            "  0% 0/3 [33:35<?, ?it/s]\n",
            "  7% 4/55 [00:46<09:49, 11.56s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1308, 'grad_norm': 0.3553019165992737, 'learning_rate': 0.00027818181818181815, 'epoch': 0.09}\n",
            "  0% 0/3 [33:47<?, ?it/s]\n",
            "  9% 5/55 [00:57<09:37, 11.56s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.114, 'grad_norm': 0.33761337399482727, 'learning_rate': 0.0002727272727272727, 'epoch': 0.11}\n",
            "  0% 0/3 [33:58<?, ?it/s]\n",
            " 11% 6/55 [01:09<09:26, 11.56s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0855, 'grad_norm': 0.39749976992607117, 'learning_rate': 0.0002672727272727272, 'epoch': 0.13}\n",
            "  0% 0/3 [34:10<?, ?it/s]\n",
            " 13% 7/55 [01:20<09:14, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0415, 'grad_norm': 0.5234705209732056, 'learning_rate': 0.0002618181818181818, 'epoch': 0.15}\n",
            "  0% 0/3 [34:22<?, ?it/s]\n",
            " 15% 8/55 [01:32<09:02, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0126, 'grad_norm': 0.4795171916484833, 'learning_rate': 0.00025636363636363633, 'epoch': 0.16}\n",
            "  0% 0/3 [34:33<?, ?it/s]\n",
            " 16% 9/55 [01:43<08:50, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0003, 'grad_norm': 0.38977766036987305, 'learning_rate': 0.00025090909090909086, 'epoch': 0.18}\n",
            "  0% 0/3 [34:45<?, ?it/s]\n",
            " 18% 10/55 [01:55<08:39, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0134, 'grad_norm': 0.3598712682723999, 'learning_rate': 0.00024545454545454545, 'epoch': 0.2}\n",
            "  0% 0/3 [34:56<?, ?it/s]\n",
            " 20% 11/55 [02:07<08:27, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9993, 'grad_norm': 0.3137359619140625, 'learning_rate': 0.00023999999999999998, 'epoch': 0.22}\n",
            "  0% 0/3 [35:08<?, ?it/s]\n",
            " 22% 12/55 [02:18<08:16, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9549, 'grad_norm': 0.2604261338710785, 'learning_rate': 0.00023454545454545454, 'epoch': 0.24}\n",
            "  0% 0/3 [35:19<?, ?it/s]\n",
            " 24% 13/55 [02:30<08:04, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9849, 'grad_norm': 0.2598434090614319, 'learning_rate': 0.00022909090909090907, 'epoch': 0.26}\n",
            "  0% 0/3 [35:31<?, ?it/s]\n",
            " 25% 14/55 [02:41<07:53, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9731, 'grad_norm': 0.23337654769420624, 'learning_rate': 0.00022363636363636363, 'epoch': 0.27}\n",
            "  0% 0/3 [35:42<?, ?it/s]\n",
            " 27% 15/55 [02:53<07:41, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9714, 'grad_norm': 0.2461453378200531, 'learning_rate': 0.00021818181818181816, 'epoch': 0.29}\n",
            "  0% 0/3 [35:54<?, ?it/s]\n",
            " 29% 16/55 [03:04<07:29, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9979, 'grad_norm': 0.25606730580329895, 'learning_rate': 0.00021272727272727272, 'epoch': 0.31}\n",
            "  0% 0/3 [36:05<?, ?it/s]\n",
            " 31% 17/55 [03:16<07:18, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.921, 'grad_norm': 0.2245519757270813, 'learning_rate': 0.00020727272727272725, 'epoch': 0.33}\n",
            "  0% 0/3 [36:17<?, ?it/s]\n",
            " 33% 18/55 [03:27<07:06, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9645, 'grad_norm': 0.1867647022008896, 'learning_rate': 0.0002018181818181818, 'epoch': 0.35}\n",
            "  0% 0/3 [36:28<?, ?it/s]\n",
            " 35% 19/55 [03:39<06:55, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9502, 'grad_norm': 0.166859433054924, 'learning_rate': 0.00019636363636363634, 'epoch': 0.37}\n",
            "  0% 0/3 [36:40<?, ?it/s]\n",
            " 36% 20/55 [03:50<06:43, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9453, 'grad_norm': 0.17082953453063965, 'learning_rate': 0.0001909090909090909, 'epoch': 0.38}\n",
            "  0% 0/3 [36:51<?, ?it/s]\n",
            " 38% 21/55 [04:02<06:32, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9562, 'grad_norm': 0.1540614515542984, 'learning_rate': 0.00018545454545454543, 'epoch': 0.4}\n",
            "  0% 0/3 [37:03<?, ?it/s]\n",
            " 40% 22/55 [04:13<06:20, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9146, 'grad_norm': 0.16062197089195251, 'learning_rate': 0.00017999999999999998, 'epoch': 0.42}\n",
            "  0% 0/3 [37:14<?, ?it/s]\n",
            " 42% 23/55 [04:25<06:08, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9211, 'grad_norm': 0.14249761402606964, 'learning_rate': 0.00017454545454545452, 'epoch': 0.44}\n",
            "  0% 0/3 [37:26<?, ?it/s]\n",
            " 44% 24/55 [04:36<05:57, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9084, 'grad_norm': 0.1511809229850769, 'learning_rate': 0.00016909090909090907, 'epoch': 0.46}\n",
            "  0% 0/3 [37:38<?, ?it/s]\n",
            " 45% 25/55 [04:48<05:45, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9549, 'grad_norm': 0.15079642832279205, 'learning_rate': 0.0001636363636363636, 'epoch': 0.47}\n",
            "  0% 0/3 [37:49<?, ?it/s]\n",
            " 47% 26/55 [04:59<05:34, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.905, 'grad_norm': 0.13708312809467316, 'learning_rate': 0.00015818181818181816, 'epoch': 0.49}\n",
            "  0% 0/3 [38:01<?, ?it/s]\n",
            " 49% 27/55 [05:11<05:22, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9051, 'grad_norm': 0.13808144629001617, 'learning_rate': 0.0001527272727272727, 'epoch': 0.51}\n",
            "  0% 0/3 [38:12<?, ?it/s]\n",
            " 51% 28/55 [05:23<05:11, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9348, 'grad_norm': 0.13556094467639923, 'learning_rate': 0.00014727272727272725, 'epoch': 0.53}\n",
            "  0% 0/3 [38:24<?, ?it/s]\n",
            " 53% 29/55 [05:34<04:59, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9273, 'grad_norm': 0.13017886877059937, 'learning_rate': 0.0001418181818181818, 'epoch': 0.55}\n",
            "  0% 0/3 [38:35<?, ?it/s]\n",
            " 55% 30/55 [05:46<04:47, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9267, 'grad_norm': 0.13041330873966217, 'learning_rate': 0.00013636363636363634, 'epoch': 0.57}\n",
            "  0% 0/3 [38:47<?, ?it/s]\n",
            " 56% 31/55 [05:57<04:36, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9399, 'grad_norm': 0.1308048665523529, 'learning_rate': 0.0001309090909090909, 'epoch': 0.58}\n",
            "  0% 0/3 [38:58<?, ?it/s]\n",
            " 58% 32/55 [06:09<04:24, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9261, 'grad_norm': 0.13496428728103638, 'learning_rate': 0.00012545454545454543, 'epoch': 0.6}\n",
            "  0% 0/3 [39:10<?, ?it/s]\n",
            " 60% 33/55 [06:20<04:13, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9208, 'grad_norm': 0.11887794733047485, 'learning_rate': 0.00011999999999999999, 'epoch': 0.62}\n",
            "  0% 0/3 [39:21<?, ?it/s]\n",
            " 62% 34/55 [06:32<04:01, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9206, 'grad_norm': 0.12418060749769211, 'learning_rate': 0.00011454545454545453, 'epoch': 0.64}\n",
            "  0% 0/3 [39:33<?, ?it/s]\n",
            " 64% 35/55 [06:43<03:50, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9616, 'grad_norm': 0.13087564706802368, 'learning_rate': 0.00010909090909090908, 'epoch': 0.66}\n",
            "  0% 0/3 [39:44<?, ?it/s]\n",
            " 65% 36/55 [06:55<03:38, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9377, 'grad_norm': 0.13412415981292725, 'learning_rate': 0.00010363636363636362, 'epoch': 0.68}\n",
            "  0% 0/3 [39:56<?, ?it/s]\n",
            " 67% 37/55 [07:06<03:27, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9101, 'grad_norm': 0.1209665983915329, 'learning_rate': 9.818181818181817e-05, 'epoch': 0.69}\n",
            "  0% 0/3 [40:07<?, ?it/s]\n",
            " 69% 38/55 [07:18<03:15, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8783, 'grad_norm': 0.1210203692317009, 'learning_rate': 9.272727272727271e-05, 'epoch': 0.71}\n",
            "  0% 0/3 [40:19<?, ?it/s]\n",
            " 71% 39/55 [07:29<03:04, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9012, 'grad_norm': 0.11460476368665695, 'learning_rate': 8.727272727272726e-05, 'epoch': 0.73}\n",
            "  0% 0/3 [40:30<?, ?it/s]\n",
            " 73% 40/55 [07:41<02:52, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9189, 'grad_norm': 0.1226089596748352, 'learning_rate': 8.18181818181818e-05, 'epoch': 0.75}\n",
            "  0% 0/3 [40:42<?, ?it/s]\n",
            " 75% 41/55 [07:52<02:41, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9121, 'grad_norm': 0.12156613916158676, 'learning_rate': 7.636363636363635e-05, 'epoch': 0.77}\n",
            "  0% 0/3 [40:53<?, ?it/s]\n",
            " 76% 42/55 [08:04<02:29, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8784, 'grad_norm': 0.11739997565746307, 'learning_rate': 7.09090909090909e-05, 'epoch': 0.79}\n",
            "  0% 0/3 [41:05<?, ?it/s]\n",
            " 78% 43/55 [08:15<02:18, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.929, 'grad_norm': 0.11003454029560089, 'learning_rate': 6.545454545454545e-05, 'epoch': 0.8}\n",
            "  0% 0/3 [41:16<?, ?it/s]\n",
            " 80% 44/55 [08:27<02:06, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9213, 'grad_norm': 0.12179090082645416, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.82}\n",
            "  0% 0/3 [41:28<?, ?it/s]\n",
            " 82% 45/55 [08:38<01:55, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9293, 'grad_norm': 0.11821306496858597, 'learning_rate': 5.454545454545454e-05, 'epoch': 0.84}\n",
            "  0% 0/3 [41:39<?, ?it/s]\n",
            " 84% 46/55 [08:50<01:43, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9452, 'grad_norm': 0.12380526959896088, 'learning_rate': 4.9090909090909084e-05, 'epoch': 0.86}\n",
            "  0% 0/3 [41:51<?, ?it/s]\n",
            " 85% 47/55 [09:01<01:32, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9275, 'grad_norm': 0.12091001868247986, 'learning_rate': 4.363636363636363e-05, 'epoch': 0.88}\n",
            "  0% 0/3 [42:02<?, ?it/s]\n",
            " 87% 48/55 [09:13<01:20, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9086, 'grad_norm': 0.11362794041633606, 'learning_rate': 3.8181818181818174e-05, 'epoch': 0.89}\n",
            "  0% 0/3 [42:14<?, ?it/s]\n",
            " 89% 49/55 [09:24<01:09, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8881, 'grad_norm': 0.11559706181287766, 'learning_rate': 3.2727272727272725e-05, 'epoch': 0.91}\n",
            "  0% 0/3 [42:25<?, ?it/s]\n",
            " 91% 50/55 [09:36<00:57, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9165, 'grad_norm': 0.1213955283164978, 'learning_rate': 2.727272727272727e-05, 'epoch': 0.93}\n",
            "  0% 0/3 [42:37<?, ?it/s]\n",
            " 93% 51/55 [09:47<00:46, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9417, 'grad_norm': 0.1146373376250267, 'learning_rate': 2.1818181818181814e-05, 'epoch': 0.95}\n",
            "  0% 0/3 [42:49<?, ?it/s]\n",
            " 95% 52/55 [09:59<00:34, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.896, 'grad_norm': 0.11085846275091171, 'learning_rate': 1.6363636363636363e-05, 'epoch': 0.97}\n",
            "  0% 0/3 [43:00<?, ?it/s]\n",
            " 96% 53/55 [10:10<00:23, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9124, 'grad_norm': 0.11359558254480362, 'learning_rate': 1.0909090909090907e-05, 'epoch': 0.99}\n",
            "  0% 0/3 [43:12<?, ?it/s]\n",
            " 98% 54/55 [10:22<00:11, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9185, 'grad_norm': 0.1308566927909851, 'learning_rate': 5.454545454545454e-06, 'epoch': 1.0}\n",
            "  0% 0/3 [43:20<?, ?it/s]\n",
            "                         \n",
            "\u001b[A{'train_runtime': 631.1502, 'train_samples_per_second': 11.089, 'train_steps_per_second': 0.087, 'train_loss': 0.9636030045422641, 'epoch': 1.0}\n",
            "  0% 0/3 [43:20<?, ?it/s]\n",
            "100% 55/55 [10:31<00:00, 11.48s/it]\n",
            "\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train split: 6999 examples [00:00, 31100.25 examples/s]\n",
            "\n",
            "Map:   0% 0/6999 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:   1% 72/6999 [00:00<00:09, 701.66 examples/s]\u001b[A\n",
            "Map:   2% 144/6999 [00:00<00:09, 707.47 examples/s]\u001b[A\n",
            "Map:   3% 217/6999 [00:00<00:09, 714.56 examples/s]\u001b[A\n",
            "Map:   4% 289/6999 [00:00<00:09, 712.73 examples/s]\u001b[A\n",
            "Map:   5% 367/6999 [00:00<00:09, 733.48 examples/s]\u001b[A\n",
            "Map:   7% 477/6999 [00:00<00:08, 729.57 examples/s]\u001b[A\n",
            "Map:   8% 558/6999 [00:00<00:08, 748.77 examples/s]\u001b[A\n",
            "Map:  10% 671/6999 [00:00<00:08, 749.29 examples/s]\u001b[A\n",
            "Map:  11% 778/6999 [00:01<00:08, 735.51 examples/s]\u001b[A\n",
            "Map:  12% 853/6999 [00:01<00:08, 736.44 examples/s]\u001b[A\n",
            "Map:  13% 936/6999 [00:01<00:08, 756.98 examples/s]\u001b[A\n",
            "Map:  15% 1035/6999 [00:01<00:11, 523.39 examples/s]\u001b[A\n",
            "Map:  16% 1106/6999 [00:01<00:10, 559.11 examples/s]\u001b[A\n",
            "Map:  17% 1179/6999 [00:01<00:09, 593.56 examples/s]\u001b[A\n",
            "Map:  18% 1247/6999 [00:01<00:09, 611.29 examples/s]\u001b[A\n",
            "Map:  19% 1330/6999 [00:01<00:08, 660.60 examples/s]\u001b[A\n",
            "Map:  20% 1428/6999 [00:02<00:08, 653.77 examples/s]\u001b[A\n",
            "Map:  22% 1506/6999 [00:02<00:08, 682.12 examples/s]\u001b[A\n",
            "Map:  23% 1579/6999 [00:02<00:07, 687.63 examples/s]\u001b[A\n",
            "Map:  24% 1686/6999 [00:02<00:07, 695.30 examples/s]\u001b[A\n",
            "Map:  25% 1760/6999 [00:02<00:07, 706.18 examples/s]\u001b[A\n",
            "Map:  26% 1847/6999 [00:02<00:06, 744.91 examples/s]\u001b[A\n",
            "Map:  28% 1954/6999 [00:02<00:06, 730.14 examples/s]\u001b[A\n",
            "Map:  29% 2031/6999 [00:03<00:09, 506.49 examples/s]\u001b[A\n",
            "Map:  30% 2098/6999 [00:03<00:09, 537.85 examples/s]\u001b[A\n",
            "Map:  31% 2182/6999 [00:03<00:07, 602.97 examples/s]\u001b[A\n",
            "Map:  33% 2286/6999 [00:03<00:07, 629.49 examples/s]\u001b[A\n",
            "Map:  34% 2355/6999 [00:03<00:07, 640.52 examples/s]\u001b[A\n",
            "Map:  35% 2426/6999 [00:03<00:06, 653.38 examples/s]\u001b[A\n",
            "Map:  36% 2502/6999 [00:03<00:06, 670.30 examples/s]\u001b[A\n",
            "Map:  37% 2580/6999 [00:03<00:06, 693.58 examples/s]\u001b[A\n",
            "Map:  38% 2686/6999 [00:04<00:06, 693.82 examples/s]\u001b[A\n",
            "Map:  40% 2792/6999 [00:04<00:06, 696.02 examples/s]\u001b[A\n",
            "Map:  41% 2872/6999 [00:04<00:05, 720.40 examples/s]\u001b[A\n",
            "Map:  42% 2949/6999 [00:04<00:05, 732.09 examples/s]\u001b[A\n",
            "Map:  43% 3039/6999 [00:04<00:07, 523.16 examples/s]\u001b[A\n",
            "Map:  44% 3108/6999 [00:04<00:07, 550.39 examples/s]\u001b[A\n",
            "Map:  45% 3183/6999 [00:04<00:06, 593.92 examples/s]\u001b[A\n",
            "Map:  47% 3255/6999 [00:04<00:06, 623.95 examples/s]\u001b[A\n",
            "Map:  48% 3326/6999 [00:05<00:05, 643.84 examples/s]\u001b[A\n",
            "Map:  49% 3399/6999 [00:05<00:05, 663.83 examples/s]\u001b[A\n",
            "Map:  50% 3475/6999 [00:05<00:05, 686.71 examples/s]\u001b[A\n",
            "Map:  51% 3547/6999 [00:05<00:04, 692.93 examples/s]\u001b[A\n",
            "Map:  52% 3621/6999 [00:05<00:04, 704.30 examples/s]\u001b[A\n",
            "Map:  53% 3699/6999 [00:05<00:04, 720.60 examples/s]\u001b[A\n",
            "Map:  54% 3810/6999 [00:05<00:04, 724.64 examples/s]\u001b[A\n",
            "Map:  56% 3886/6999 [00:05<00:04, 728.32 examples/s]\u001b[A\n",
            "Map:  57% 3964/6999 [00:05<00:04, 736.67 examples/s]\u001b[A\n",
            "Map:  58% 4039/6999 [00:06<00:05, 504.22 examples/s]\u001b[A\n",
            "Map:  59% 4114/6999 [00:06<00:05, 555.21 examples/s]\u001b[A\n",
            "Map:  60% 4192/6999 [00:06<00:04, 606.53 examples/s]\u001b[A\n",
            "Map:  61% 4269/6999 [00:06<00:04, 646.64 examples/s]\u001b[A\n",
            "Map:  62% 4343/6999 [00:06<00:03, 669.90 examples/s]\u001b[A\n",
            "Map:  63% 4419/6999 [00:06<00:03, 692.74 examples/s]\u001b[A\n",
            "Map:  64% 4497/6999 [00:06<00:03, 711.73 examples/s]\u001b[A\n",
            "Map:  66% 4603/6999 [00:06<00:03, 704.79 examples/s]\u001b[A\n",
            "Map:  67% 4710/6999 [00:07<00:03, 697.57 examples/s]\u001b[A\n",
            "Map:  68% 4782/6999 [00:07<00:03, 701.50 examples/s]\u001b[A\n",
            "Map:  70% 4890/6999 [00:07<00:02, 703.68 examples/s]\u001b[A\n",
            "Map:  71% 4967/6999 [00:07<00:02, 718.85 examples/s]\u001b[A\n",
            "Map:  73% 5081/6999 [00:07<00:03, 538.62 examples/s]\u001b[A\n",
            "Map:  74% 5158/6999 [00:07<00:03, 580.10 examples/s]\u001b[A\n",
            "Map:  75% 5229/6999 [00:08<00:02, 602.86 examples/s]\u001b[A\n",
            "Map:  76% 5305/6999 [00:08<00:02, 637.21 examples/s]\u001b[A\n",
            "Map:  77% 5415/6999 [00:08<00:02, 664.91 examples/s]\u001b[A\n",
            "Map:  79% 5514/6999 [00:08<00:02, 660.21 examples/s]\u001b[A\n",
            "Map:  80% 5592/6999 [00:08<00:02, 684.31 examples/s]\u001b[A\n",
            "Map:  81% 5669/6999 [00:08<00:01, 704.47 examples/s]\u001b[A\n",
            "Map:  82% 5745/6999 [00:08<00:01, 713.25 examples/s]\u001b[A\n",
            "Map:  84% 5854/6999 [00:08<00:01, 714.70 examples/s]\u001b[A\n",
            "Map:  85% 5927/6999 [00:08<00:01, 712.51 examples/s]\u001b[A\n",
            "Map:  86% 6000/6999 [00:09<00:01, 517.17 examples/s]\u001b[A\n",
            "Map:  87% 6080/6999 [00:09<00:01, 572.79 examples/s]\u001b[A\n",
            "Map:  88% 6154/6999 [00:09<00:01, 608.07 examples/s]\u001b[A\n",
            "Map:  89% 6224/6999 [00:09<00:01, 626.33 examples/s]\u001b[A\n",
            "Map:  90% 6300/6999 [00:09<00:01, 659.61 examples/s]\u001b[A\n",
            "Map:  91% 6376/6999 [00:09<00:00, 684.08 examples/s]\u001b[A\n",
            "Map:  92% 6450/6999 [00:09<00:00, 696.22 examples/s]\u001b[A\n",
            "Map:  93% 6522/6999 [00:09<00:00, 701.32 examples/s]\u001b[A\n",
            "Map:  94% 6597/6999 [00:10<00:00, 714.17 examples/s]\u001b[A\n",
            "Map:  95% 6677/6999 [00:10<00:00, 731.50 examples/s]\u001b[A\n",
            "Map:  97% 6757/6999 [00:10<00:00, 747.99 examples/s]\u001b[A\n",
            "Map:  98% 6840/6999 [00:10<00:00, 771.19 examples/s]\u001b[A\n",
            "Map: 100% 6999/6999 [00:10<00:00, 651.41 examples/s]\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "                         \n",
            "\u001b[A{'loss': 1.2493, 'grad_norm': 0.42737817764282227, 'learning_rate': 0.0003, 'epoch': 0.02}\n",
            "  0% 0/3 [43:44<?, ?it/s]\n",
            "  2% 1/55 [00:11<10:24, 11.57s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1753, 'grad_norm': 0.4114353358745575, 'learning_rate': 0.0002945454545454545, 'epoch': 0.04}\n",
            "  0% 0/3 [43:56<?, ?it/s]\n",
            "  4% 2/55 [00:23<10:11, 11.54s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1558, 'grad_norm': 0.4551272392272949, 'learning_rate': 0.00028909090909090904, 'epoch': 0.05}\n",
            "  0% 0/3 [44:07<?, ?it/s]\n",
            "  5% 3/55 [00:34<09:59, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1793, 'grad_norm': 0.3608056902885437, 'learning_rate': 0.0002836363636363636, 'epoch': 0.07}\n",
            "  0% 0/3 [44:19<?, ?it/s]\n",
            "  7% 4/55 [00:46<09:47, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0972, 'grad_norm': 0.36143866181373596, 'learning_rate': 0.00027818181818181815, 'epoch': 0.09}\n",
            "  0% 0/3 [44:30<?, ?it/s]\n",
            "  9% 5/55 [00:57<09:35, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0949, 'grad_norm': 0.33600619435310364, 'learning_rate': 0.0002727272727272727, 'epoch': 0.11}\n",
            "  0% 0/3 [44:42<?, ?it/s]\n",
            " 11% 6/55 [01:09<09:24, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0762, 'grad_norm': 0.3850400745868683, 'learning_rate': 0.0002672727272727272, 'epoch': 0.13}\n",
            "  0% 0/3 [44:53<?, ?it/s]\n",
            " 13% 7/55 [01:20<09:12, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0603, 'grad_norm': 0.49019891023635864, 'learning_rate': 0.0002618181818181818, 'epoch': 0.15}\n",
            "  0% 0/3 [45:05<?, ?it/s]\n",
            " 15% 8/55 [01:32<09:01, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.059, 'grad_norm': 0.5963674783706665, 'learning_rate': 0.00025636363636363633, 'epoch': 0.16}\n",
            "  0% 0/3 [45:16<?, ?it/s]\n",
            " 16% 9/55 [01:43<08:49, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0108, 'grad_norm': 0.38437914848327637, 'learning_rate': 0.00025090909090909086, 'epoch': 0.18}\n",
            "  0% 0/3 [45:28<?, ?it/s]\n",
            " 18% 10/55 [01:55<08:38, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0227, 'grad_norm': 0.3797016739845276, 'learning_rate': 0.00024545454545454545, 'epoch': 0.2}\n",
            "  0% 0/3 [45:39<?, ?it/s]\n",
            " 20% 11/55 [02:06<08:26, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9738, 'grad_norm': 0.3110498785972595, 'learning_rate': 0.00023999999999999998, 'epoch': 0.22}\n",
            "  0% 0/3 [45:51<?, ?it/s]\n",
            " 22% 12/55 [02:18<08:15, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9768, 'grad_norm': 0.2619626522064209, 'learning_rate': 0.00023454545454545454, 'epoch': 0.24}\n",
            "  0% 0/3 [46:03<?, ?it/s]\n",
            " 24% 13/55 [02:29<08:03, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9655, 'grad_norm': 0.2544512152671814, 'learning_rate': 0.00022909090909090907, 'epoch': 0.26}\n",
            "  0% 0/3 [46:14<?, ?it/s]\n",
            " 25% 14/55 [02:41<07:52, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9732, 'grad_norm': 0.2428111732006073, 'learning_rate': 0.00022363636363636363, 'epoch': 0.27}\n",
            "  0% 0/3 [46:26<?, ?it/s]\n",
            " 27% 15/55 [02:52<07:40, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0176, 'grad_norm': 0.2242346853017807, 'learning_rate': 0.00021818181818181816, 'epoch': 0.29}\n",
            "  0% 0/3 [46:37<?, ?it/s]\n",
            " 29% 16/55 [03:04<07:29, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9376, 'grad_norm': 0.2341901659965515, 'learning_rate': 0.00021272727272727272, 'epoch': 0.31}\n",
            "  0% 0/3 [46:49<?, ?it/s]\n",
            " 31% 17/55 [03:15<07:17, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9483, 'grad_norm': 0.18966925144195557, 'learning_rate': 0.00020727272727272725, 'epoch': 0.33}\n",
            "  0% 0/3 [47:00<?, ?it/s]\n",
            " 33% 18/55 [03:27<07:06, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9635, 'grad_norm': 0.18758414685726166, 'learning_rate': 0.0002018181818181818, 'epoch': 0.35}\n",
            "  0% 0/3 [47:12<?, ?it/s]\n",
            " 35% 19/55 [03:38<06:54, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9308, 'grad_norm': 0.1782456487417221, 'learning_rate': 0.00019636363636363634, 'epoch': 0.37}\n",
            "  0% 0/3 [47:23<?, ?it/s]\n",
            " 36% 20/55 [03:50<06:43, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9435, 'grad_norm': 0.16197311878204346, 'learning_rate': 0.0001909090909090909, 'epoch': 0.38}\n",
            "  0% 0/3 [47:35<?, ?it/s]\n",
            " 38% 21/55 [04:01<06:31, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9001, 'grad_norm': 0.15192177891731262, 'learning_rate': 0.00018545454545454543, 'epoch': 0.4}\n",
            "  0% 0/3 [47:46<?, ?it/s]\n",
            " 40% 22/55 [04:13<06:20, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.936, 'grad_norm': 0.1440930813550949, 'learning_rate': 0.00017999999999999998, 'epoch': 0.42}\n",
            "  0% 0/3 [47:58<?, ?it/s]\n",
            " 42% 23/55 [04:24<06:08, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.939, 'grad_norm': 0.1510467380285263, 'learning_rate': 0.00017454545454545452, 'epoch': 0.44}\n",
            "  0% 0/3 [48:09<?, ?it/s]\n",
            " 44% 24/55 [04:36<05:57, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9424, 'grad_norm': 0.14147965610027313, 'learning_rate': 0.00016909090909090907, 'epoch': 0.46}\n",
            "  0% 0/3 [48:21<?, ?it/s]\n",
            " 45% 25/55 [04:47<05:45, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9211, 'grad_norm': 0.1383945643901825, 'learning_rate': 0.0001636363636363636, 'epoch': 0.47}\n",
            "  0% 0/3 [48:32<?, ?it/s]\n",
            " 47% 26/55 [04:59<05:33, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9555, 'grad_norm': 0.13585814833641052, 'learning_rate': 0.00015818181818181816, 'epoch': 0.49}\n",
            "  0% 0/3 [48:44<?, ?it/s]\n",
            " 49% 27/55 [05:10<05:22, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9387, 'grad_norm': 0.13170133531093597, 'learning_rate': 0.0001527272727272727, 'epoch': 0.51}\n",
            "  0% 0/3 [48:55<?, ?it/s]\n",
            " 51% 28/55 [05:22<05:10, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8895, 'grad_norm': 0.12815554440021515, 'learning_rate': 0.00014727272727272725, 'epoch': 0.53}\n",
            "  0% 0/3 [49:07<?, ?it/s]\n",
            " 53% 29/55 [05:34<04:59, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9252, 'grad_norm': 0.12669111788272858, 'learning_rate': 0.0001418181818181818, 'epoch': 0.55}\n",
            "  0% 0/3 [49:18<?, ?it/s]\n",
            " 55% 30/55 [05:45<04:47, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9238, 'grad_norm': 0.1288367360830307, 'learning_rate': 0.00013636363636363634, 'epoch': 0.57}\n",
            "  0% 0/3 [49:30<?, ?it/s]\n",
            " 56% 31/55 [05:57<04:36, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9445, 'grad_norm': 0.13107112050056458, 'learning_rate': 0.0001309090909090909, 'epoch': 0.58}\n",
            "  0% 0/3 [49:41<?, ?it/s]\n",
            " 58% 32/55 [06:08<04:24, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9153, 'grad_norm': 0.12183626741170883, 'learning_rate': 0.00012545454545454543, 'epoch': 0.6}\n",
            "  0% 0/3 [49:53<?, ?it/s]\n",
            " 60% 33/55 [06:20<04:13, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8954, 'grad_norm': 0.12139876931905746, 'learning_rate': 0.00011999999999999999, 'epoch': 0.62}\n",
            "  0% 0/3 [50:04<?, ?it/s]\n",
            " 62% 34/55 [06:31<04:01, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9161, 'grad_norm': 0.11790654808282852, 'learning_rate': 0.00011454545454545453, 'epoch': 0.64}\n",
            "  0% 0/3 [50:16<?, ?it/s]\n",
            " 64% 35/55 [06:43<03:50, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.953, 'grad_norm': 0.12796981632709503, 'learning_rate': 0.00010909090909090908, 'epoch': 0.66}\n",
            "  0% 0/3 [50:27<?, ?it/s]\n",
            " 65% 36/55 [06:54<03:38, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.941, 'grad_norm': 0.1193329319357872, 'learning_rate': 0.00010363636363636362, 'epoch': 0.68}\n",
            "  0% 0/3 [50:39<?, ?it/s]\n",
            " 67% 37/55 [07:06<03:27, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9239, 'grad_norm': 0.12404992431402206, 'learning_rate': 9.818181818181817e-05, 'epoch': 0.69}\n",
            "  0% 0/3 [50:50<?, ?it/s]\n",
            " 69% 38/55 [07:17<03:15, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9359, 'grad_norm': 0.11233866214752197, 'learning_rate': 9.272727272727271e-05, 'epoch': 0.71}\n",
            "  0% 0/3 [51:02<?, ?it/s]\n",
            " 71% 39/55 [07:29<03:04, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9538, 'grad_norm': 0.12468591332435608, 'learning_rate': 8.727272727272726e-05, 'epoch': 0.73}\n",
            "  0% 0/3 [51:13<?, ?it/s]\n",
            " 73% 40/55 [07:40<02:52, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9343, 'grad_norm': 0.12538783252239227, 'learning_rate': 8.18181818181818e-05, 'epoch': 0.75}\n",
            "  0% 0/3 [51:25<?, ?it/s]\n",
            " 75% 41/55 [07:52<02:40, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9269, 'grad_norm': 0.11696142703294754, 'learning_rate': 7.636363636363635e-05, 'epoch': 0.77}\n",
            "  0% 0/3 [51:36<?, ?it/s]\n",
            " 76% 42/55 [08:03<02:29, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9669, 'grad_norm': 0.11994936317205429, 'learning_rate': 7.09090909090909e-05, 'epoch': 0.79}\n",
            "  0% 0/3 [51:48<?, ?it/s]\n",
            " 78% 43/55 [08:15<02:18, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9282, 'grad_norm': 0.11830589920282364, 'learning_rate': 6.545454545454545e-05, 'epoch': 0.8}\n",
            "  0% 0/3 [51:59<?, ?it/s]\n",
            " 80% 44/55 [08:26<02:06, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9613, 'grad_norm': 0.1158575788140297, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.82}\n",
            "  0% 0/3 [52:11<?, ?it/s]\n",
            " 82% 45/55 [08:38<01:55, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8941, 'grad_norm': 0.11952190846204758, 'learning_rate': 5.454545454545454e-05, 'epoch': 0.84}\n",
            "  0% 0/3 [52:22<?, ?it/s]\n",
            " 84% 46/55 [08:49<01:43, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9119, 'grad_norm': 0.11931871622800827, 'learning_rate': 4.9090909090909084e-05, 'epoch': 0.86}\n",
            "  0% 0/3 [52:34<?, ?it/s]\n",
            " 85% 47/55 [09:01<01:31, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9363, 'grad_norm': 0.1280905157327652, 'learning_rate': 4.363636363636363e-05, 'epoch': 0.88}\n",
            "  0% 0/3 [52:45<?, ?it/s]\n",
            " 87% 48/55 [09:12<01:20, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9345, 'grad_norm': 0.12519627809524536, 'learning_rate': 3.8181818181818174e-05, 'epoch': 0.89}\n",
            "  0% 0/3 [52:57<?, ?it/s]\n",
            " 89% 49/55 [09:24<01:09, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9371, 'grad_norm': 0.11430832743644714, 'learning_rate': 3.2727272727272725e-05, 'epoch': 0.91}\n",
            "  0% 0/3 [53:08<?, ?it/s]\n",
            " 91% 50/55 [09:35<00:57, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9058, 'grad_norm': 0.11499816924333572, 'learning_rate': 2.727272727272727e-05, 'epoch': 0.93}\n",
            "  0% 0/3 [53:20<?, ?it/s]\n",
            " 93% 51/55 [09:47<00:45, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.8901, 'grad_norm': 0.11003487557172775, 'learning_rate': 2.1818181818181814e-05, 'epoch': 0.95}\n",
            "  0% 0/3 [53:31<?, ?it/s]\n",
            " 95% 52/55 [09:58<00:34, 11.49s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9347, 'grad_norm': 0.11385179311037064, 'learning_rate': 1.6363636363636363e-05, 'epoch': 0.97}\n",
            "  0% 0/3 [53:43<?, ?it/s]\n",
            " 96% 53/55 [10:10<00:22, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9339, 'grad_norm': 0.11775092035531998, 'learning_rate': 1.0909090909090907e-05, 'epoch': 0.99}\n",
            "  0% 0/3 [53:54<?, ?it/s]\n",
            " 98% 54/55 [10:21<00:11, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9193, 'grad_norm': 0.14378789067268372, 'learning_rate': 5.454545454545454e-06, 'epoch': 1.0}\n",
            "  0% 0/3 [54:02<?, ?it/s]\n",
            "                         \n",
            "\u001b[A{'train_runtime': 630.115, 'train_samples_per_second': 11.107, 'train_steps_per_second': 0.087, 'train_loss': 0.9704853198745034, 'epoch': 1.0}\n",
            "  0% 0/3 [54:03<?, ?it/s]\n",
            "100% 55/55 [10:30<00:00, 11.46s/it]\n",
            "\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train split: 6999 examples [00:00, 28517.05 examples/s]\n",
            "\n",
            "Map:   0% 0/6999 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:   1% 72/6999 [00:00<00:09, 698.46 examples/s]\u001b[A\n",
            "Map:   2% 147/6999 [00:00<00:09, 726.14 examples/s]\u001b[A\n",
            "Map:   4% 252/6999 [00:00<00:09, 708.68 examples/s]\u001b[A\n",
            "Map:   5% 365/6999 [00:00<00:09, 722.70 examples/s]\u001b[A\n",
            "Map:   7% 465/6999 [00:00<00:09, 696.14 examples/s]\u001b[A\n",
            "Map:   8% 566/6999 [00:00<00:09, 686.52 examples/s]\u001b[A\n",
            "Map:   9% 643/6999 [00:00<00:09, 703.88 examples/s]\u001b[A\n",
            "Map:  10% 718/6999 [00:01<00:08, 714.20 examples/s]\u001b[A\n",
            "Map:  12% 825/6999 [00:01<00:08, 708.95 examples/s]\u001b[A\n",
            "Map:  13% 901/6999 [00:01<00:08, 719.91 examples/s]\u001b[A\n",
            "Map:  14% 976/6999 [00:01<00:08, 724.74 examples/s]\u001b[A\n",
            "Map:  15% 1067/6999 [00:01<00:11, 498.42 examples/s]\u001b[A\n",
            "Map:  16% 1145/6999 [00:01<00:10, 554.44 examples/s]\u001b[A\n",
            "Map:  18% 1246/6999 [00:01<00:09, 588.41 examples/s]\u001b[A\n",
            "Map:  19% 1317/6999 [00:02<00:09, 613.37 examples/s]\u001b[A\n",
            "Map:  20% 1392/6999 [00:02<00:08, 643.99 examples/s]\u001b[A\n",
            "Map:  21% 1464/6999 [00:02<00:08, 661.55 examples/s]\u001b[A\n",
            "Map:  22% 1544/6999 [00:02<00:07, 695.56 examples/s]\u001b[A\n",
            "Map:  23% 1619/6999 [00:02<00:07, 708.23 examples/s]\u001b[A\n",
            "Map:  25% 1720/6999 [00:02<00:07, 690.55 examples/s]\u001b[A\n",
            "Map:  26% 1831/6999 [00:02<00:07, 702.19 examples/s]\u001b[A\n",
            "Map:  28% 1935/6999 [00:02<00:07, 696.85 examples/s]\u001b[A\n",
            "Map:  29% 2035/6999 [00:03<00:09, 511.79 examples/s]\u001b[A\n",
            "Map:  30% 2102/6999 [00:03<00:09, 538.30 examples/s]\u001b[A\n",
            "Map:  31% 2175/6999 [00:03<00:08, 575.79 examples/s]\u001b[A\n",
            "Map:  32% 2245/6999 [00:03<00:07, 602.61 examples/s]\u001b[A\n",
            "Map:  33% 2316/6999 [00:03<00:07, 628.12 examples/s]\u001b[A\n",
            "Map:  34% 2391/6999 [00:03<00:07, 656.23 examples/s]\u001b[A\n",
            "Map:  35% 2466/6999 [00:03<00:06, 679.76 examples/s]\u001b[A\n",
            "Map:  36% 2542/6999 [00:03<00:06, 697.10 examples/s]\u001b[A\n",
            "Map:  37% 2614/6999 [00:04<00:06, 700.79 examples/s]\u001b[A\n",
            "Map:  39% 2725/6999 [00:04<00:05, 712.50 examples/s]\u001b[A\n",
            "Map:  40% 2831/6999 [00:04<00:05, 705.04 examples/s]\u001b[A\n",
            "Map:  42% 2905/6999 [00:04<00:05, 705.97 examples/s]\u001b[A\n",
            "Map:  43% 3000/6999 [00:04<00:07, 503.23 examples/s]\u001b[A\n",
            "Map:  44% 3076/6999 [00:04<00:07, 551.78 examples/s]\u001b[A\n",
            "Map:  45% 3149/6999 [00:04<00:06, 590.08 examples/s]\u001b[A\n",
            "Map:  46% 3248/6999 [00:05<00:06, 605.18 examples/s]\u001b[A\n",
            "Map:  47% 3322/6999 [00:05<00:05, 634.54 examples/s]\u001b[A\n",
            "Map:  49% 3395/6999 [00:05<00:05, 656.64 examples/s]\u001b[A\n",
            "Map:  50% 3467/6999 [00:05<00:05, 672.33 examples/s]\u001b[A\n",
            "Map:  51% 3542/6999 [00:05<00:05, 689.47 examples/s]\u001b[A\n",
            "Map:  52% 3653/6999 [00:05<00:04, 705.40 examples/s]\u001b[A\n",
            "Map:  53% 3729/6999 [00:05<00:04, 715.88 examples/s]\u001b[A\n",
            "Map:  54% 3811/6999 [00:05<00:04, 741.61 examples/s]\u001b[A\n",
            "Map:  56% 3887/6999 [00:05<00:04, 742.85 examples/s]\u001b[A\n",
            "Map:  57% 3965/6999 [00:06<00:04, 750.53 examples/s]\u001b[A\n",
            "Map:  58% 4074/6999 [00:06<00:05, 524.85 examples/s]\u001b[A\n",
            "Map:  59% 4157/6999 [00:06<00:04, 584.68 examples/s]\u001b[A\n",
            "Map:  61% 4262/6999 [00:06<00:04, 614.06 examples/s]\u001b[A\n",
            "Map:  62% 4342/6999 [00:06<00:04, 653.27 examples/s]\u001b[A\n",
            "Map:  63% 4418/6999 [00:06<00:03, 676.51 examples/s]\u001b[A\n",
            "Map:  65% 4516/6999 [00:06<00:03, 663.59 examples/s]\u001b[A\n",
            "Map:  66% 4589/6999 [00:07<00:03, 679.60 examples/s]\u001b[A\n",
            "Map:  67% 4668/6999 [00:07<00:03, 707.12 examples/s]\u001b[A\n",
            "Map:  68% 4777/6999 [00:07<00:03, 711.16 examples/s]\u001b[A\n",
            "Map:  69% 4855/6999 [00:07<00:02, 725.91 examples/s]\u001b[A\n",
            "Map:  70% 4931/6999 [00:07<00:02, 731.90 examples/s]\u001b[A\n",
            "Map:  72% 5036/6999 [00:07<00:03, 527.51 examples/s]\u001b[A\n",
            "Map:  73% 5108/6999 [00:07<00:03, 564.75 examples/s]\u001b[A\n",
            "Map:  74% 5179/6999 [00:08<00:03, 595.25 examples/s]\u001b[A\n",
            "Map:  75% 5249/6999 [00:08<00:02, 619.46 examples/s]\u001b[A\n",
            "Map:  76% 5320/6999 [00:08<00:02, 640.43 examples/s]\u001b[A\n",
            "Map:  77% 5401/6999 [00:08<00:02, 681.44 examples/s]\u001b[A\n",
            "Map:  78% 5478/6999 [00:08<00:02, 703.00 examples/s]\u001b[A\n",
            "Map:  79% 5553/6999 [00:08<00:02, 713.32 examples/s]\u001b[A\n",
            "Map:  80% 5634/6999 [00:08<00:01, 737.25 examples/s]\u001b[A\n",
            "Map:  82% 5742/6999 [00:08<00:01, 722.13 examples/s]\u001b[A\n",
            "Map:  83% 5818/6999 [00:08<00:01, 730.25 examples/s]\u001b[A\n",
            "Map:  85% 5923/6999 [00:09<00:01, 717.48 examples/s]\u001b[A\n",
            "Map:  86% 6000/6999 [00:09<00:01, 504.30 examples/s]\u001b[A\n",
            "Map:  87% 6073/6999 [00:09<00:01, 548.41 examples/s]\u001b[A\n",
            "Map:  88% 6144/6999 [00:09<00:01, 584.23 examples/s]\u001b[A\n",
            "Map:  89% 6218/6999 [00:09<00:01, 620.05 examples/s]\u001b[A\n",
            "Map:  90% 6290/6999 [00:09<00:01, 643.74 examples/s]\u001b[A\n",
            "Map:  91% 6365/6999 [00:09<00:00, 671.26 examples/s]\u001b[A\n",
            "Map:  92% 6447/6999 [00:09<00:00, 710.35 examples/s]\u001b[A\n",
            "Map:  93% 6527/6999 [00:10<00:00, 732.53 examples/s]\u001b[A\n",
            "Map:  95% 6635/6999 [00:10<00:00, 723.99 examples/s]\u001b[A\n",
            "Map:  96% 6749/6999 [00:10<00:00, 730.01 examples/s]\u001b[A\n",
            "Map:  98% 6827/6999 [00:10<00:00, 737.55 examples/s]\u001b[A\n",
            "Map: 100% 6999/6999 [00:10<00:00, 643.32 examples/s]\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "                         \n",
            "\u001b[A{'loss': 1.2318, 'grad_norm': 0.4388386011123657, 'learning_rate': 0.0003, 'epoch': 0.02}\n",
            "  0% 0/3 [54:27<?, ?it/s]\n",
            "  2% 1/55 [00:11<10:23, 11.55s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.2016, 'grad_norm': 0.4066532850265503, 'learning_rate': 0.0002945454545454545, 'epoch': 0.04}\n",
            "  0% 0/3 [54:39<?, ?it/s]\n",
            "  4% 2/55 [00:23<10:11, 11.53s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.2013, 'grad_norm': 0.4326540529727936, 'learning_rate': 0.00028909090909090904, 'epoch': 0.05}\n",
            "  0% 0/3 [54:50<?, ?it/s]\n",
            "  5% 3/55 [00:34<09:59, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1496, 'grad_norm': 0.3733968436717987, 'learning_rate': 0.0002836363636363636, 'epoch': 0.07}\n",
            "  0% 0/3 [55:02<?, ?it/s]\n",
            "  7% 4/55 [00:46<09:47, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1319, 'grad_norm': 0.341019868850708, 'learning_rate': 0.00027818181818181815, 'epoch': 0.09}\n",
            "  0% 0/3 [55:13<?, ?it/s]\n",
            "  9% 5/55 [00:57<09:36, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.1029, 'grad_norm': 0.32363733649253845, 'learning_rate': 0.0002727272727272727, 'epoch': 0.11}\n",
            "  0% 0/3 [55:25<?, ?it/s]\n",
            " 11% 6/55 [01:09<09:24, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.074, 'grad_norm': 0.3676851689815521, 'learning_rate': 0.0002672727272727272, 'epoch': 0.13}\n",
            "  0% 0/3 [55:36<?, ?it/s]\n",
            " 13% 7/55 [01:20<09:12, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0917, 'grad_norm': 0.4100413918495178, 'learning_rate': 0.0002618181818181818, 'epoch': 0.15}\n",
            "  0% 0/3 [55:48<?, ?it/s]\n",
            " 15% 8/55 [01:32<09:01, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.024, 'grad_norm': 0.6418176293373108, 'learning_rate': 0.00025636363636363633, 'epoch': 0.16}\n",
            "  0% 0/3 [55:59<?, ?it/s]\n",
            " 16% 9/55 [01:43<08:49, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0218, 'grad_norm': 0.35844114422798157, 'learning_rate': 0.00025090909090909086, 'epoch': 0.18}\n",
            "  0% 0/3 [56:11<?, ?it/s]\n",
            " 18% 10/55 [01:55<08:38, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0029, 'grad_norm': 0.38753437995910645, 'learning_rate': 0.00024545454545454545, 'epoch': 0.2}\n",
            "  0% 0/3 [56:22<?, ?it/s]\n",
            " 20% 11/55 [02:06<08:26, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 1.0302, 'grad_norm': 0.320991575717926, 'learning_rate': 0.00023999999999999998, 'epoch': 0.22}\n",
            "  0% 0/3 [56:34<?, ?it/s]\n",
            " 22% 12/55 [02:18<08:14, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9838, 'grad_norm': 0.2622883915901184, 'learning_rate': 0.00023454545454545454, 'epoch': 0.24}\n",
            "  0% 0/3 [56:45<?, ?it/s]\n",
            " 24% 13/55 [02:29<08:03, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9752, 'grad_norm': 0.24941681325435638, 'learning_rate': 0.00022909090909090907, 'epoch': 0.26}\n",
            "  0% 0/3 [56:57<?, ?it/s]\n",
            " 25% 14/55 [02:41<07:51, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9859, 'grad_norm': 0.2652518153190613, 'learning_rate': 0.00022363636363636363, 'epoch': 0.27}\n",
            "  0% 0/3 [57:08<?, ?it/s]\n",
            " 27% 15/55 [02:52<07:40, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9281, 'grad_norm': 0.24220165610313416, 'learning_rate': 0.00021818181818181816, 'epoch': 0.29}\n",
            "  0% 0/3 [57:20<?, ?it/s]\n",
            " 29% 16/55 [03:04<07:28, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9317, 'grad_norm': 0.20532259345054626, 'learning_rate': 0.00021272727272727272, 'epoch': 0.31}\n",
            "  0% 0/3 [57:31<?, ?it/s]\n",
            " 31% 17/55 [03:15<07:17, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9619, 'grad_norm': 0.21215522289276123, 'learning_rate': 0.00020727272727272725, 'epoch': 0.33}\n",
            "  0% 0/3 [57:43<?, ?it/s]\n",
            " 33% 18/55 [03:27<07:05, 11.50s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9156, 'grad_norm': 0.18551909923553467, 'learning_rate': 0.0002018181818181818, 'epoch': 0.35}\n",
            "  0% 0/3 [57:54<?, ?it/s]\n",
            " 35% 19/55 [03:38<06:54, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9636, 'grad_norm': 0.17745041847229004, 'learning_rate': 0.00019636363636363634, 'epoch': 0.37}\n",
            "  0% 0/3 [58:06<?, ?it/s]\n",
            " 36% 20/55 [03:50<06:43, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9081, 'grad_norm': 0.15914051234722137, 'learning_rate': 0.0001909090909090909, 'epoch': 0.38}\n",
            "  0% 0/3 [58:17<?, ?it/s]\n",
            " 38% 21/55 [04:01<06:31, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.931, 'grad_norm': 0.160628542304039, 'learning_rate': 0.00018545454545454543, 'epoch': 0.4}\n",
            "  0% 0/3 [58:29<?, ?it/s]\n",
            " 40% 22/55 [04:13<06:19, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9479, 'grad_norm': 0.1481422781944275, 'learning_rate': 0.00017999999999999998, 'epoch': 0.42}\n",
            "  0% 0/3 [58:40<?, ?it/s]\n",
            " 42% 23/55 [04:24<06:08, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9164, 'grad_norm': 0.14742793142795563, 'learning_rate': 0.00017454545454545452, 'epoch': 0.44}\n",
            "  0% 0/3 [58:52<?, ?it/s]\n",
            " 44% 24/55 [04:36<05:56, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9457, 'grad_norm': 0.1349843144416809, 'learning_rate': 0.00016909090909090907, 'epoch': 0.46}\n",
            "  0% 0/3 [59:03<?, ?it/s]\n",
            " 45% 25/55 [04:47<05:45, 11.51s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9481, 'grad_norm': 0.14073392748832703, 'learning_rate': 0.0001636363636363636, 'epoch': 0.47}\n",
            "  0% 0/3 [59:15<?, ?it/s]\n",
            " 47% 26/55 [04:59<05:34, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9193, 'grad_norm': 0.14351288974285126, 'learning_rate': 0.00015818181818181816, 'epoch': 0.49}\n",
            "  0% 0/3 [59:26<?, ?it/s]\n",
            " 49% 27/55 [05:10<05:22, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9265, 'grad_norm': 0.1315213143825531, 'learning_rate': 0.0001527272727272727, 'epoch': 0.51}\n",
            "  0% 0/3 [59:38<?, ?it/s]\n",
            " 51% 28/55 [05:22<05:11, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9551, 'grad_norm': 0.1390116959810257, 'learning_rate': 0.00014727272727272725, 'epoch': 0.53}\n",
            "  0% 0/3 [59:50<?, ?it/s]\n",
            " 53% 29/55 [05:33<04:59, 11.52s/it]\u001b[A\n",
            "                         \n",
            "\u001b[A{'loss': 0.9531, 'grad_norm': 0.13223868608474731, 'learning_rate': 0.0001418181818181818, 'epoch': 0.55}\n",
            "  0% 0/3 [1:00:01<?, ?it/s]\n",
            " 55% 30/55 [05:45<04:48, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9683, 'grad_norm': 0.1319369077682495, 'learning_rate': 0.00013636363636363634, 'epoch': 0.57}\n",
            "  0% 0/3 [1:00:13<?, ?it/s]\n",
            " 56% 31/55 [05:56<04:36, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9505, 'grad_norm': 0.13612060248851776, 'learning_rate': 0.0001309090909090909, 'epoch': 0.58}\n",
            "  0% 0/3 [1:00:24<?, ?it/s]\n",
            " 58% 32/55 [06:08<04:24, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9649, 'grad_norm': 0.13106629252433777, 'learning_rate': 0.00012545454545454543, 'epoch': 0.6}\n",
            "  0% 0/3 [1:00:36<?, ?it/s]\n",
            " 60% 33/55 [06:19<04:13, 11.51s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9484, 'grad_norm': 0.1233404204249382, 'learning_rate': 0.00011999999999999999, 'epoch': 0.62}\n",
            "  0% 0/3 [1:00:47<?, ?it/s]\n",
            " 62% 34/55 [06:31<04:02, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9167, 'grad_norm': 0.13086512684822083, 'learning_rate': 0.00011454545454545453, 'epoch': 0.64}\n",
            "  0% 0/3 [1:00:59<?, ?it/s]\n",
            " 64% 35/55 [06:43<03:50, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9262, 'grad_norm': 0.12096772342920303, 'learning_rate': 0.00010909090909090908, 'epoch': 0.66}\n",
            "  0% 0/3 [1:01:10<?, ?it/s]\n",
            " 65% 36/55 [06:54<03:39, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9204, 'grad_norm': 0.11856496334075928, 'learning_rate': 0.00010363636363636362, 'epoch': 0.68}\n",
            "  0% 0/3 [1:01:22<?, ?it/s]\n",
            " 67% 37/55 [07:06<03:27, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9418, 'grad_norm': 0.13264100253582, 'learning_rate': 9.818181818181817e-05, 'epoch': 0.69}\n",
            "  0% 0/3 [1:01:33<?, ?it/s]\n",
            " 69% 38/55 [07:17<03:15, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.886, 'grad_norm': 0.11363781243562698, 'learning_rate': 9.272727272727271e-05, 'epoch': 0.71}\n",
            "  0% 0/3 [1:01:45<?, ?it/s]\n",
            " 71% 39/55 [07:29<03:04, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.936, 'grad_norm': 0.12232577800750732, 'learning_rate': 8.727272727272726e-05, 'epoch': 0.73}\n",
            "  0% 0/3 [1:01:56<?, ?it/s]\n",
            " 73% 40/55 [07:40<02:52, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9236, 'grad_norm': 0.12327710539102554, 'learning_rate': 8.18181818181818e-05, 'epoch': 0.75}\n",
            "  0% 0/3 [1:02:08<?, ?it/s]\n",
            " 75% 41/55 [07:52<02:41, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.92, 'grad_norm': 0.11440762132406235, 'learning_rate': 7.636363636363635e-05, 'epoch': 0.77}\n",
            "  0% 0/3 [1:02:19<?, ?it/s]\n",
            " 76% 42/55 [08:03<02:29, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9502, 'grad_norm': 0.11837758868932724, 'learning_rate': 7.09090909090909e-05, 'epoch': 0.79}\n",
            "  0% 0/3 [1:02:31<?, ?it/s]\n",
            " 78% 43/55 [08:15<02:18, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.8989, 'grad_norm': 0.113617442548275, 'learning_rate': 6.545454545454545e-05, 'epoch': 0.8}\n",
            "  0% 0/3 [1:02:42<?, ?it/s]\n",
            " 80% 44/55 [08:26<02:06, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9436, 'grad_norm': 0.11362909525632858, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.82}\n",
            "  0% 0/3 [1:02:54<?, ?it/s]\n",
            " 82% 45/55 [08:38<01:55, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.8927, 'grad_norm': 0.12213370949029922, 'learning_rate': 5.454545454545454e-05, 'epoch': 0.84}\n",
            "  0% 0/3 [1:03:06<?, ?it/s]\n",
            " 84% 46/55 [08:49<01:43, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9144, 'grad_norm': 0.11855294555425644, 'learning_rate': 4.9090909090909084e-05, 'epoch': 0.86}\n",
            "  0% 0/3 [1:03:17<?, ?it/s]\n",
            " 85% 47/55 [09:01<01:32, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.8976, 'grad_norm': 0.11873360723257065, 'learning_rate': 4.363636363636363e-05, 'epoch': 0.88}\n",
            "  0% 0/3 [1:03:29<?, ?it/s]\n",
            " 87% 48/55 [09:13<01:20, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9304, 'grad_norm': 0.12761326134204865, 'learning_rate': 3.8181818181818174e-05, 'epoch': 0.89}\n",
            "  0% 0/3 [1:03:40<?, ?it/s]\n",
            " 89% 49/55 [09:24<01:09, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.912, 'grad_norm': 0.11939428746700287, 'learning_rate': 3.2727272727272725e-05, 'epoch': 0.91}\n",
            "  0% 0/3 [1:03:52<?, ?it/s]\n",
            " 91% 50/55 [09:36<00:57, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9443, 'grad_norm': 0.12083268165588379, 'learning_rate': 2.727272727272727e-05, 'epoch': 0.93}\n",
            "  0% 0/3 [1:04:03<?, ?it/s]\n",
            " 93% 51/55 [09:47<00:46, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.922, 'grad_norm': 0.11667681485414505, 'learning_rate': 2.1818181818181814e-05, 'epoch': 0.95}\n",
            "  0% 0/3 [1:04:15<?, ?it/s]\n",
            " 95% 52/55 [09:59<00:34, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9283, 'grad_norm': 0.1141696348786354, 'learning_rate': 1.6363636363636363e-05, 'epoch': 0.97}\n",
            "  0% 0/3 [1:04:26<?, ?it/s]\n",
            " 96% 53/55 [10:10<00:23, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9137, 'grad_norm': 0.1171182245016098, 'learning_rate': 1.0909090909090907e-05, 'epoch': 0.99}\n",
            "  0% 0/3 [1:04:38<?, ?it/s]\n",
            " 98% 54/55 [10:22<00:11, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9099, 'grad_norm': 0.13319405913352966, 'learning_rate': 5.454545454545454e-06, 'epoch': 1.0}\n",
            "  0% 0/3 [1:04:46<?, ?it/s]\n",
            "                           \n",
            "\u001b[A{'train_runtime': 631.0467, 'train_samples_per_second': 11.091, 'train_steps_per_second': 0.087, 'train_loss': 0.9712956125086004, 'epoch': 1.0}\n",
            "  0% 0/3 [1:04:47<?, ?it/s]\n",
            "100% 55/55 [10:31<00:00, 11.47s/it]\n",
            "\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train split: 6999 examples [00:00, 30588.24 examples/s]\n",
            "\n",
            "Map:   0% 0/6999 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:   1% 75/6999 [00:00<00:09, 719.42 examples/s]\u001b[A\n",
            "Map:   2% 148/6999 [00:00<00:09, 715.05 examples/s]\u001b[A\n",
            "Map:   4% 252/6999 [00:00<00:09, 698.17 examples/s]\u001b[A\n",
            "Map:   5% 328/6999 [00:00<00:09, 717.63 examples/s]\u001b[A\n",
            "Map:   6% 435/6999 [00:00<00:09, 710.05 examples/s]\u001b[A\n",
            "Map:   8% 537/6999 [00:00<00:09, 695.08 examples/s]\u001b[A\n",
            "Map:   9% 614/6999 [00:00<00:08, 711.76 examples/s]\u001b[A\n",
            "Map:  10% 687/6999 [00:00<00:08, 715.23 examples/s]\u001b[A\n",
            "Map:  11% 761/6999 [00:01<00:08, 716.76 examples/s]\u001b[A\n",
            "Map:  12% 842/6999 [00:01<00:08, 740.49 examples/s]\u001b[A\n",
            "Map:  13% 918/6999 [00:01<00:08, 744.68 examples/s]\u001b[A\n",
            "Map:  14% 1000/6999 [00:01<00:12, 497.51 examples/s]\u001b[A\n",
            "Map:  15% 1064/6999 [00:01<00:11, 526.54 examples/s]\u001b[A\n",
            "Map:  16% 1144/6999 [00:01<00:10, 583.93 examples/s]\u001b[A\n",
            "Map:  17% 1216/6999 [00:01<00:09, 614.66 examples/s]\u001b[A\n",
            "Map:  18% 1287/6999 [00:01<00:08, 638.54 examples/s]\u001b[A\n",
            "Map:  19% 1363/6999 [00:02<00:08, 667.82 examples/s]\u001b[A\n",
            "Map:  21% 1445/6999 [00:02<00:07, 708.47 examples/s]\u001b[A\n",
            "Map:  22% 1562/6999 [00:02<00:07, 733.14 examples/s]\u001b[A\n",
            "Map:  23% 1639/6999 [00:02<00:07, 739.70 examples/s]\u001b[A\n",
            "Map:  25% 1748/6999 [00:02<00:07, 730.94 examples/s]\u001b[A\n",
            "Map:  26% 1852/6999 [00:02<00:07, 713.42 examples/s]\u001b[A\n",
            "Map:  28% 1961/6999 [00:02<00:07, 715.04 examples/s]\u001b[A\n",
            "Map:  29% 2060/6999 [00:03<00:10, 493.23 examples/s]\u001b[A\n",
            "Map:  31% 2139/6999 [00:03<00:10, 471.76 examples/s]\u001b[A\n",
            "Map:  32% 2206/6999 [00:03<00:09, 505.90 examples/s]\u001b[A\n",
            "Map:  32% 2270/6999 [00:03<00:08, 530.32 examples/s]\u001b[A\n",
            "Map:  33% 2335/6999 [00:03<00:08, 556.22 examples/s]\u001b[A\n",
            "Map:  34% 2411/6999 [00:03<00:07, 604.21 examples/s]\u001b[A\n",
            "Map:  36% 2491/6999 [00:03<00:06, 648.20 examples/s]\u001b[A\n",
            "Map:  37% 2564/6999 [00:04<00:06, 665.80 examples/s]\u001b[A\n",
            "Map:  38% 2646/6999 [00:04<00:06, 705.22 examples/s]\u001b[A\n",
            "Map:  39% 2720/6999 [00:04<00:06, 711.11 examples/s]\u001b[A\n",
            "Map:  40% 2799/6999 [00:04<00:05, 729.90 examples/s]\u001b[A\n",
            "Map:  42% 2905/6999 [00:04<00:05, 715.52 examples/s]\u001b[A\n",
            "Map:  43% 3000/6999 [00:04<00:07, 510.11 examples/s]\u001b[A\n",
            "Map:  44% 3075/6999 [00:04<00:07, 555.64 examples/s]\u001b[A\n",
            "Map:  45% 3143/6999 [00:04<00:06, 582.79 examples/s]\u001b[A\n",
            "Map:  46% 3221/6999 [00:05<00:06, 626.84 examples/s]\u001b[A\n",
            "Map:  47% 3291/6999 [00:05<00:05, 643.16 examples/s]\u001b[A\n",
            "Map:  48% 3361/6999 [00:05<00:05, 656.51 examples/s]\u001b[A\n",
            "Map:  49% 3431/6999 [00:05<00:05, 664.93 examples/s]\u001b[A\n",
            "Map:  50% 3527/6999 [00:05<00:05, 652.02 examples/s]\u001b[A\n",
            "Map:  51% 3601/6999 [00:05<00:05, 673.32 examples/s]\u001b[A\n",
            "Map:  52% 3674/6999 [00:05<00:04, 684.41 examples/s]\u001b[A\n",
            "Map:  54% 3752/6999 [00:05<00:04, 706.64 examples/s]\u001b[A\n",
            "Map:  55% 3860/6999 [00:06<00:04, 702.09 examples/s]\u001b[A\n",
            "Map:  56% 3934/6999 [00:06<00:04, 709.24 examples/s]\u001b[A\n",
            "Map:  58% 4032/6999 [00:06<00:06, 493.53 examples/s]\u001b[A\n",
            "Map:  59% 4112/6999 [00:06<00:05, 552.40 examples/s]\u001b[A\n",
            "Map:  60% 4179/6999 [00:06<00:04, 575.60 examples/s]\u001b[A\n",
            "Map:  61% 4254/6999 [00:06<00:04, 612.08 examples/s]\u001b[A\n",
            "Map:  62% 4332/6999 [00:06<00:04, 649.81 examples/s]\u001b[A\n",
            "Map:  63% 4428/6999 [00:06<00:04, 641.01 examples/s]\u001b[A\n",
            "Map:  64% 4504/6999 [00:07<00:03, 666.48 examples/s]\u001b[A\n",
            "Map:  65% 4575/6999 [00:07<00:03, 672.26 examples/s]\u001b[A\n",
            "Map:  66% 4654/6999 [00:07<00:03, 699.14 examples/s]\u001b[A\n",
            "Map:  68% 4771/6999 [00:07<00:03, 724.97 examples/s]\u001b[A\n",
            "Map:  69% 4853/6999 [00:07<00:02, 745.71 examples/s]\u001b[A\n",
            "Map:  71% 4939/6999 [00:07<00:02, 774.90 examples/s]\u001b[A\n",
            "Map:  72% 5039/6999 [00:07<00:03, 553.73 examples/s]\u001b[A\n",
            "Map:  73% 5116/6999 [00:08<00:03, 596.75 examples/s]\u001b[A\n",
            "Map:  75% 5217/6999 [00:08<00:02, 618.34 examples/s]\u001b[A\n",
            "Map:  76% 5292/6999 [00:08<00:02, 646.93 examples/s]\u001b[A\n",
            "Map:  77% 5366/6999 [00:08<00:02, 667.03 examples/s]\u001b[A\n",
            "Map:  78% 5441/6999 [00:08<00:02, 685.04 examples/s]\u001b[A\n",
            "Map:  79% 5521/6999 [00:08<00:02, 713.93 examples/s]\u001b[A\n",
            "Map:  80% 5630/6999 [00:08<00:01, 713.06 examples/s]\u001b[A\n",
            "Map:  82% 5740/6999 [00:08<00:01, 719.47 examples/s]\u001b[A\n",
            "Map:  83% 5816/6999 [00:08<00:01, 728.19 examples/s]\u001b[A\n",
            "Map:  85% 5929/6999 [00:09<00:01, 735.00 examples/s]\u001b[A\n",
            "Map:  86% 6033/6999 [00:09<00:01, 538.33 examples/s]\u001b[A\n",
            "Map:  87% 6110/6999 [00:09<00:01, 581.40 examples/s]\u001b[A\n",
            "Map:  88% 6183/6999 [00:09<00:01, 609.79 examples/s]\u001b[A\n",
            "Map:  90% 6281/6999 [00:09<00:01, 619.73 examples/s]\u001b[A\n",
            "Map:  91% 6357/6999 [00:09<00:00, 648.53 examples/s]\u001b[A\n",
            "Map:  92% 6465/6999 [00:10<00:00, 669.51 examples/s]\u001b[A\n",
            "Map:  93% 6540/6999 [00:10<00:00, 683.87 examples/s]\u001b[A\n",
            "Map:  94% 6612/6999 [00:10<00:00, 689.22 examples/s]\u001b[A\n",
            "Map:  96% 6693/6999 [00:10<00:00, 718.36 examples/s]\u001b[A\n",
            "Map:  97% 6767/6999 [00:10<00:00, 720.18 examples/s]\u001b[A\n",
            "Map:  98% 6846/6999 [00:10<00:00, 737.10 examples/s]\u001b[A\n",
            "Map: 100% 6999/6999 [00:10<00:00, 637.80 examples/s]\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "                           \n",
            "\u001b[A{'loss': 1.3065, 'grad_norm': 0.4396291673183441, 'learning_rate': 0.0003, 'epoch': 0.02}\n",
            "  0% 0/3 [1:05:11<?, ?it/s]\n",
            "  2% 1/55 [00:11<10:24, 11.56s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.218, 'grad_norm': 0.42139142751693726, 'learning_rate': 0.0002945454545454545, 'epoch': 0.04}\n",
            "  0% 0/3 [1:05:23<?, ?it/s]\n",
            "  4% 2/55 [00:23<10:11, 11.55s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.1446, 'grad_norm': 0.44543734192848206, 'learning_rate': 0.00028909090909090904, 'epoch': 0.05}\n",
            "  0% 0/3 [1:05:34<?, ?it/s]\n",
            "  5% 3/55 [00:34<10:00, 11.55s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.1277, 'grad_norm': 0.35914748907089233, 'learning_rate': 0.0002836363636363636, 'epoch': 0.07}\n",
            "  0% 0/3 [1:05:46<?, ?it/s]\n",
            "  7% 4/55 [00:46<09:49, 11.55s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.0587, 'grad_norm': 0.3140464425086975, 'learning_rate': 0.00027818181818181815, 'epoch': 0.09}\n",
            "  0% 0/3 [1:05:57<?, ?it/s]\n",
            "  9% 5/55 [00:57<09:37, 11.55s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.0597, 'grad_norm': 0.3435938358306885, 'learning_rate': 0.0002727272727272727, 'epoch': 0.11}\n",
            "  0% 0/3 [1:06:09<?, ?it/s]\n",
            " 11% 6/55 [01:09<09:25, 11.55s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.1066, 'grad_norm': 0.3821018934249878, 'learning_rate': 0.0002672727272727272, 'epoch': 0.13}\n",
            "  0% 0/3 [1:06:20<?, ?it/s]\n",
            " 13% 7/55 [01:20<09:13, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.0697, 'grad_norm': 0.473020076751709, 'learning_rate': 0.0002618181818181818, 'epoch': 0.15}\n",
            "  0% 0/3 [1:06:32<?, ?it/s]\n",
            " 15% 8/55 [01:32<09:01, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.094, 'grad_norm': 0.5720126032829285, 'learning_rate': 0.00025636363636363633, 'epoch': 0.16}\n",
            "  0% 0/3 [1:06:43<?, ?it/s]\n",
            " 16% 9/55 [01:43<08:50, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9761, 'grad_norm': 0.37921467423439026, 'learning_rate': 0.00025090909090909086, 'epoch': 0.18}\n",
            "  0% 0/3 [1:06:55<?, ?it/s]\n",
            " 18% 10/55 [01:55<08:38, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.0093, 'grad_norm': 0.35468271374702454, 'learning_rate': 0.00024545454545454545, 'epoch': 0.2}\n",
            "  0% 0/3 [1:07:06<?, ?it/s]\n",
            " 20% 11/55 [02:06<08:27, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 1.016, 'grad_norm': 0.3061898648738861, 'learning_rate': 0.00023999999999999998, 'epoch': 0.22}\n",
            "  0% 0/3 [1:07:18<?, ?it/s]\n",
            " 22% 12/55 [02:18<08:15, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9506, 'grad_norm': 0.26167237758636475, 'learning_rate': 0.00023454545454545454, 'epoch': 0.24}\n",
            "  0% 0/3 [1:07:29<?, ?it/s]\n",
            " 24% 13/55 [02:29<08:04, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9721, 'grad_norm': 0.2624913454055786, 'learning_rate': 0.00022909090909090907, 'epoch': 0.26}\n",
            "  0% 0/3 [1:07:41<?, ?it/s]\n",
            " 25% 14/55 [02:41<07:52, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9623, 'grad_norm': 0.2623462975025177, 'learning_rate': 0.00022363636363636363, 'epoch': 0.27}\n",
            "  0% 0/3 [1:07:53<?, ?it/s]\n",
            " 27% 15/55 [02:53<07:41, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9675, 'grad_norm': 0.2758096158504486, 'learning_rate': 0.00021818181818181816, 'epoch': 0.29}\n",
            "  0% 0/3 [1:08:04<?, ?it/s]\n",
            " 29% 16/55 [03:04<07:30, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9377, 'grad_norm': 0.23417381942272186, 'learning_rate': 0.00021272727272727272, 'epoch': 0.31}\n",
            "  0% 0/3 [1:08:16<?, ?it/s]\n",
            " 31% 17/55 [03:16<07:18, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9475, 'grad_norm': 0.22332380712032318, 'learning_rate': 0.00020727272727272725, 'epoch': 0.33}\n",
            "  0% 0/3 [1:08:27<?, ?it/s]\n",
            " 33% 18/55 [03:27<07:06, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9204, 'grad_norm': 0.20362460613250732, 'learning_rate': 0.0002018181818181818, 'epoch': 0.35}\n",
            "  0% 0/3 [1:08:39<?, ?it/s]\n",
            " 35% 19/55 [03:39<06:54, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9259, 'grad_norm': 0.1772485077381134, 'learning_rate': 0.00019636363636363634, 'epoch': 0.37}\n",
            "  0% 0/3 [1:08:50<?, ?it/s]\n",
            " 36% 20/55 [03:50<06:43, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9395, 'grad_norm': 0.15861175954341888, 'learning_rate': 0.0001909090909090909, 'epoch': 0.38}\n",
            "  0% 0/3 [1:09:02<?, ?it/s]\n",
            " 38% 21/55 [04:02<06:31, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9178, 'grad_norm': 0.15039373934268951, 'learning_rate': 0.00018545454545454543, 'epoch': 0.4}\n",
            "  0% 0/3 [1:09:13<?, ?it/s]\n",
            " 40% 22/55 [04:13<06:20, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.97, 'grad_norm': 0.14857065677642822, 'learning_rate': 0.00017999999999999998, 'epoch': 0.42}\n",
            "  0% 0/3 [1:09:25<?, ?it/s]\n",
            " 42% 23/55 [04:25<06:08, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9594, 'grad_norm': 0.16430221498012543, 'learning_rate': 0.00017454545454545452, 'epoch': 0.44}\n",
            "  0% 0/3 [1:09:36<?, ?it/s]\n",
            " 44% 24/55 [04:36<05:57, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9492, 'grad_norm': 0.1421157568693161, 'learning_rate': 0.00016909090909090907, 'epoch': 0.46}\n",
            "  0% 0/3 [1:09:48<?, ?it/s]\n",
            " 45% 25/55 [04:48<05:45, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9125, 'grad_norm': 0.13728120923042297, 'learning_rate': 0.0001636363636363636, 'epoch': 0.47}\n",
            "  0% 0/3 [1:09:59<?, ?it/s]\n",
            " 47% 26/55 [04:59<05:34, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9165, 'grad_norm': 0.1507740616798401, 'learning_rate': 0.00015818181818181816, 'epoch': 0.49}\n",
            "  0% 0/3 [1:10:11<?, ?it/s]\n",
            " 49% 27/55 [05:11<05:22, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9019, 'grad_norm': 0.1348501592874527, 'learning_rate': 0.0001527272727272727, 'epoch': 0.51}\n",
            "  0% 0/3 [1:10:22<?, ?it/s]\n",
            " 51% 28/55 [05:22<05:11, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9047, 'grad_norm': 0.12865939736366272, 'learning_rate': 0.00014727272727272725, 'epoch': 0.53}\n",
            "  0% 0/3 [1:10:34<?, ?it/s]\n",
            " 53% 29/55 [05:34<04:59, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.955, 'grad_norm': 0.13852708041667938, 'learning_rate': 0.0001418181818181818, 'epoch': 0.55}\n",
            "  0% 0/3 [1:10:45<?, ?it/s]\n",
            " 55% 30/55 [05:45<04:48, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9326, 'grad_norm': 0.127019003033638, 'learning_rate': 0.00013636363636363634, 'epoch': 0.57}\n",
            "  0% 0/3 [1:10:57<?, ?it/s]\n",
            " 56% 31/55 [05:57<04:36, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9255, 'grad_norm': 0.12778042256832123, 'learning_rate': 0.0001309090909090909, 'epoch': 0.58}\n",
            "  0% 0/3 [1:11:08<?, ?it/s]\n",
            " 58% 32/55 [06:09<04:25, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9602, 'grad_norm': 0.12344349175691605, 'learning_rate': 0.00012545454545454543, 'epoch': 0.6}\n",
            "  0% 0/3 [1:11:20<?, ?it/s]\n",
            " 60% 33/55 [06:20<04:13, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9277, 'grad_norm': 0.119068443775177, 'learning_rate': 0.00011999999999999999, 'epoch': 0.62}\n",
            "  0% 0/3 [1:11:32<?, ?it/s]\n",
            " 62% 34/55 [06:32<04:02, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.8905, 'grad_norm': 0.12291374802589417, 'learning_rate': 0.00011454545454545453, 'epoch': 0.64}\n",
            "  0% 0/3 [1:11:43<?, ?it/s]\n",
            " 64% 35/55 [06:43<03:50, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9096, 'grad_norm': 0.12306001782417297, 'learning_rate': 0.00010909090909090908, 'epoch': 0.66}\n",
            "  0% 0/3 [1:11:55<?, ?it/s]\n",
            " 65% 36/55 [06:55<03:39, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9303, 'grad_norm': 0.12709112465381622, 'learning_rate': 0.00010363636363636362, 'epoch': 0.68}\n",
            "  0% 0/3 [1:12:06<?, ?it/s]\n",
            " 67% 37/55 [07:06<03:27, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9378, 'grad_norm': 0.1249258816242218, 'learning_rate': 9.818181818181817e-05, 'epoch': 0.69}\n",
            "  0% 0/3 [1:12:18<?, ?it/s]\n",
            " 69% 38/55 [07:18<03:16, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.879, 'grad_norm': 0.11977831274271011, 'learning_rate': 9.272727272727271e-05, 'epoch': 0.71}\n",
            "  0% 0/3 [1:12:29<?, ?it/s]\n",
            " 71% 39/55 [07:29<03:04, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9517, 'grad_norm': 0.12177165597677231, 'learning_rate': 8.727272727272726e-05, 'epoch': 0.73}\n",
            "  0% 0/3 [1:12:41<?, ?it/s]\n",
            " 73% 40/55 [07:41<02:52, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9246, 'grad_norm': 0.12045998871326447, 'learning_rate': 8.18181818181818e-05, 'epoch': 0.75}\n",
            "  0% 0/3 [1:12:52<?, ?it/s]\n",
            " 75% 41/55 [07:52<02:41, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9493, 'grad_norm': 0.11856574565172195, 'learning_rate': 7.636363636363635e-05, 'epoch': 0.77}\n",
            "  0% 0/3 [1:13:04<?, ?it/s]\n",
            " 76% 42/55 [08:04<02:29, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9175, 'grad_norm': 0.11884970963001251, 'learning_rate': 7.09090909090909e-05, 'epoch': 0.79}\n",
            "  0% 0/3 [1:13:15<?, ?it/s]\n",
            " 78% 43/55 [08:15<02:18, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.939, 'grad_norm': 0.11660962551832199, 'learning_rate': 6.545454545454545e-05, 'epoch': 0.8}\n",
            "  0% 0/3 [1:13:27<?, ?it/s]\n",
            " 80% 44/55 [08:27<02:06, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.8918, 'grad_norm': 0.11225561052560806, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.82}\n",
            "  0% 0/3 [1:13:38<?, ?it/s]\n",
            " 82% 45/55 [08:38<01:55, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9057, 'grad_norm': 0.11466677486896515, 'learning_rate': 5.454545454545454e-05, 'epoch': 0.84}\n",
            "  0% 0/3 [1:13:50<?, ?it/s]\n",
            " 84% 46/55 [08:50<01:43, 11.54s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9287, 'grad_norm': 0.11531747132539749, 'learning_rate': 4.9090909090909084e-05, 'epoch': 0.86}\n",
            "  0% 0/3 [1:14:01<?, ?it/s]\n",
            " 85% 47/55 [09:02<01:32, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9275, 'grad_norm': 0.12156020849943161, 'learning_rate': 4.363636363636363e-05, 'epoch': 0.88}\n",
            "  0% 0/3 [1:14:13<?, ?it/s]\n",
            " 87% 48/55 [09:13<01:20, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9275, 'grad_norm': 0.11880761384963989, 'learning_rate': 3.8181818181818174e-05, 'epoch': 0.89}\n",
            "  0% 0/3 [1:14:24<?, ?it/s]\n",
            " 89% 49/55 [09:25<01:09, 11.53s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9314, 'grad_norm': 0.11458129435777664, 'learning_rate': 3.2727272727272725e-05, 'epoch': 0.91}\n",
            "  0% 0/3 [1:14:36<?, ?it/s]\n",
            " 91% 50/55 [09:36<00:57, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9588, 'grad_norm': 0.12353310734033585, 'learning_rate': 2.727272727272727e-05, 'epoch': 0.93}\n",
            "  0% 0/3 [1:14:47<?, ?it/s]\n",
            " 93% 51/55 [09:48<00:46, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.8774, 'grad_norm': 0.11309713125228882, 'learning_rate': 2.1818181818181814e-05, 'epoch': 0.95}\n",
            "  0% 0/3 [1:14:59<?, ?it/s]\n",
            " 95% 52/55 [09:59<00:34, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9005, 'grad_norm': 0.11286722868680954, 'learning_rate': 1.6363636363636363e-05, 'epoch': 0.97}\n",
            "  0% 0/3 [1:15:11<?, ?it/s]\n",
            " 96% 53/55 [10:11<00:23, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9118, 'grad_norm': 0.1126711443066597, 'learning_rate': 1.0909090909090907e-05, 'epoch': 0.99}\n",
            "  0% 0/3 [1:15:22<?, ?it/s]\n",
            " 98% 54/55 [10:22<00:11, 11.52s/it]\u001b[A\n",
            "                           \n",
            "\u001b[A{'loss': 0.9253, 'grad_norm': 0.13607624173164368, 'learning_rate': 5.454545454545454e-06, 'epoch': 1.0}\n",
            "  0% 0/3 [1:15:30<?, ?it/s]\n",
            "                           \n",
            "\u001b[A{'train_runtime': 631.2248, 'train_samples_per_second': 11.088, 'train_steps_per_second': 0.087, 'train_loss': 0.9665261268615722, 'epoch': 1.0}\n",
            "  0% 0/3 [1:15:31<?, ?it/s]\n",
            "100% 55/55 [10:31<00:00, 11.48s/it]\n",
            "\n",
            "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train split: 6999 examples [00:00, 30928.75 examples/s]\n",
            "\n",
            "Map:   0% 0/6999 [00:00<?, ? examples/s]\u001b[A\n",
            "Map:   1% 70/6999 [00:00<00:10, 685.03 examples/s]\u001b[A\n",
            "Map:   2% 144/6999 [00:00<00:09, 709.01 examples/s]\u001b[A\n",
            "Map:   3% 225/6999 [00:00<00:09, 750.62 examples/s]\u001b[A\n",
            "Map:   5% 330/6999 [00:00<00:09, 721.70 examples/s]\u001b[A\n",
            "Map:   6% 442/6999 [00:00<00:09, 725.97 examples/s]\u001b[A\n",
            "Map:   7% 516/6999 [00:00<00:08, 727.59 examples/s]\u001b[A\n",
            "Map:   8% 593/6999 [00:00<00:08, 738.39 examples/s]\u001b[A\n",
            "Map:  10% 700/6999 [00:00<00:08, 725.83 examples/s]\u001b[A\n",
            "Map:  11% 774/6999 [00:01<00:08, 724.91 examples/s]\u001b[A\n",
            "Map:  12% 851/6999 [00:01<00:08, 735.35 examples/s]\u001b[A\n",
            "Map:  13% 929/6999 [00:01<00:08, 747.63 examples/s]\u001b[A\n",
            "Map:  15% 1037/6999 [00:01<00:11, 518.71 examples/s]\u001b[A\n",
            "Map:  16% 1117/6999 [00:01<00:10, 572.84 examples/s]\u001b[A\n",
            "Map:  17% 1194/6999 [00:01<00:09, 614.27 examples/s]\u001b[A\n",
            "Map:  18% 1280/6999 [00:01<00:08, 671.89 examples/s]\u001b[A\n",
            "Map:  20% 1394/6999 [00:02<00:08, 697.15 examples/s]\u001b[A\n",
            "Map:  21% 1471/6999 [00:02<00:07, 713.47 examples/s]\u001b[A\n",
            "Map:  22% 1552/6999 [00:02<00:07, 737.07 examples/s]\u001b[A\n",
            "Map:  24% 1657/6999 [00:02<00:07, 721.23 examples/s]\u001b[A\n",
            "Map:  25% 1772/6999 [00:02<00:07, 732.48 examples/s]\u001b[A\n",
            "Map:  27% 1883/6999 [00:02<00:07, 730.53 examples/s]\u001b[A\n",
            "Map:  28% 1959/6999 [00:02<00:06, 733.30 examples/s]\u001b[A\n",
            "Map:  29% 2034/6999 [00:03<00:09, 512.62 examples/s]\u001b[A\n",
            "Map:  30% 2107/6999 [00:03<00:08, 554.09 examples/s]\u001b[A\n",
            "Map:  31% 2183/6999 [00:03<00:08, 597.94 examples/s]\u001b[A\n",
            "Map:  32% 2260/6999 [00:03<00:07, 635.89 examples/s]\u001b[A\n",
            "Map:  33% 2338/6999 [00:03<00:06, 668.07 examples/s]\u001b[A\n",
            "Map:  34% 2411/6999 [00:03<00:06, 681.28 examples/s]\u001b[A\n",
            "Map:  36% 2497/6999 [00:03<00:06, 727.52 examples/s]\u001b[A\n",
            "Map:  37% 2573/6999 [00:03<00:06, 731.82 examples/s]\u001b[A\n",
            "Map:  38% 2659/6999 [00:03<00:05, 765.95 examples/s]\u001b[A\n",
            "Map:  40% 2773/6999 [00:04<00:05, 759.88 examples/s]\u001b[A\n",
            "Map:  41% 2872/6999 [00:04<00:05, 719.18 examples/s]\u001b[A\n",
            "Map:  42% 2952/6999 [00:04<00:05, 737.19 examples/s]\u001b[A\n",
            "Map:  43% 3035/6999 [00:04<00:07, 532.35 examples/s]\u001b[A\n",
            "Map:  44% 3109/6999 [00:04<00:06, 573.68 examples/s]\u001b[A\n",
            "Map:  46% 3186/6999 [00:04<00:06, 613.48 examples/s]\u001b[A\n",
            "Map:  47% 3263/6999 [00:04<00:05, 647.08 examples/s]\u001b[A\n",
            "Map:  48% 3337/6999 [00:04<00:05, 669.57 examples/s]\u001b[A\n",
            "Map:  49% 3411/6999 [00:05<00:05, 686.62 examples/s]\u001b[A\n",
            "Map:  50% 3487/6999 [00:05<00:04, 706.74 examples/s]\u001b[A\n",
            "Map:  51% 3561/6999 [00:05<00:04, 713.71 examples/s]\u001b[A\n",
            "Map:  52% 3663/6999 [00:05<00:04, 695.41 examples/s]\u001b[A\n",
            "Map:  53% 3744/6999 [00:05<00:04, 723.50 examples/s]\u001b[A\n",
            "Map:  55% 3852/6999 [00:05<00:04, 716.83 examples/s]\u001b[A\n",
            "Map:  56% 3933/6999 [00:05<00:04, 739.94 examples/s]\u001b[A\n",
            "Map:  58% 4037/6999 [00:06<00:05, 533.78 examples/s]\u001b[A\n",
            "Map:  59% 4109/6999 [00:06<00:05, 568.76 examples/s]\u001b[A\n",
            "Map:  60% 4187/6999 [00:06<00:04, 613.48 examples/s]\u001b[A\n",
            "Map:  61% 4256/6999 [00:06<00:04, 628.49 examples/s]\u001b[A\n",
            "Map:  62% 4326/6999 [00:06<00:04, 639.01 examples/s]\u001b[A\n",
            "Map:  63% 4428/6999 [00:06<00:03, 652.47 examples/s]\u001b[A\n",
            "Map:  64% 4504/6999 [00:06<00:03, 677.30 examples/s]\u001b[A\n",
            "Map:  65% 4580/6999 [00:06<00:03, 691.80 examples/s]\u001b[A\n",
            "Map:  66% 4654/6999 [00:06<00:03, 699.77 examples/s]\u001b[A\n",
            "Map:  68% 4727/6999 [00:07<00:03, 706.68 examples/s]\u001b[A\n",
            "Map:  69% 4804/6999 [00:07<00:03, 721.33 examples/s]\u001b[A\n",
            "Map:  70% 4906/6999 [00:07<00:02, 703.90 examples/s]\u001b[A\n",
            "Map:  71% 4988/6999 [00:07<00:02, 730.07 examples/s]\u001b[A\n",
            "Map:  73% 5076/6999 [00:07<00:03, 513.43 examples/s]\u001b[A\n",
            "Map:  74% 5149/6999 [00:07<00:03, 555.97 examples/s]\u001b[A\n",
            "Map:  75% 5223/6999 [00:07<00:02, 597.06 examples/s]\u001b[A\n",
            "Map:  76% 5291/6999 [00:07<00:02, 616.43 examples/s]\u001b[A\n",
            "Map:  77% 5360/6999 [00:08<00:02, 630.45 examples/s]\u001b[A\n",
            "Map:  78% 5430/6999 [00:08<00:02, 648.00 examples/s]\u001b[A\n",
            "Map:  79% 5510/6999 [00:08<00:02, 683.84 examples/s]\u001b[A\n",
            "Map:  80% 5585/6999 [00:08<00:02, 696.73 examples/s]\u001b[A\n",
            "Map:  81% 5658/6999 [00:08<00:01, 700.88 examples/s]\u001b[A\n",
            "Map:  82% 5767/6999 [00:08<00:01, 705.62 examples/s]\u001b[A\n",
            "Map:  83% 5843/6999 [00:08<00:01, 715.42 examples/s]\u001b[A\n",
            "Map:  85% 5920/6999 [00:08<00:01, 726.30 examples/s]\u001b[A\n",
            "Map:  86% 6000/6999 [00:09<00:01, 513.74 examples/s]\u001b[A\n",
            "Map:  87% 6072/6999 [00:09<00:01, 553.54 examples/s]\u001b[A\n",
            "Map:  88% 6149/6999 [00:09<00:01, 599.47 examples/s]\u001b[A\n",
            "Map:  89% 6219/6999 [00:09<00:01, 622.22 examples/s]\u001b[A\n",
            "Map:  90% 6302/6999 [00:09<00:01, 675.14 examples/s]\u001b[A\n",
            "Map:  91% 6400/6999 [00:09<00:00, 662.57 examples/s]\u001b[A\n",
            "Map:  93% 6477/6999 [00:09<00:00, 687.89 examples/s]\u001b[A\n",
            "Map:  94% 6585/6999 [00:09<00:00, 694.47 examples/s]\u001b[A\n",
            "Map:  95% 6661/6999 [00:10<00:00, 710.03 examples/s]\u001b[A\n",
            "Map:  96% 6736/6999 [00:10<00:00, 717.44 examples/s]\u001b[A\n",
            "Map:  97% 6812/6999 [00:10<00:00, 727.45 examples/s]\u001b[A\n",
            "Map:  98% 6890/6999 [00:10<00:00, 737.32 examples/s]\u001b[A"
          ]
        }
      ]
    }
  ]
}